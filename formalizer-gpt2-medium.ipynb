{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hearlvein/formalizer/blob/main/formalizer-gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e78fb2",
      "metadata": {
        "id": "85e78fb2"
      },
      "source": [
        "# ðŸŽ¯ Fine-Tuning GPT-2 for Formality Translation with Few-Shot Prompting\n",
        "\n",
        "This notebook guides you through fine-tuning GPT-2 to translate informal text to formal text using few-shot prompting. The process includes:\n",
        "- Dataset preparation from valentin_dataset.csv\n",
        "- Few-shot prompt engineering for formality translation\n",
        "- Model fine-tuning with LoRA\n",
        "- Interactive formality translation testing\n",
        "\n",
        "**Task:** Given an informal sentence, generate its formal equivalent using in-context learning.\n",
        "\n",
        "**Note:** This notebook is designed for execution in Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38cb754d",
      "metadata": {
        "id": "38cb754d"
      },
      "source": [
        "## ðŸ”§ Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4dc4a906",
      "metadata": {
        "id": "4dc4a906",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13aaf1f6-a3f3-40eb-9ab7-f2a59025d3a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/366.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m366.4/366.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m424.6/424.6 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install -q transformers datasets peft trl accelerate bitsandbytes optimum\n",
        "!pip install -q pandas scikit-learn nltk matplotlib\n",
        "!pip install -q tf-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05b944d2",
      "metadata": {
        "id": "05b944d2"
      },
      "source": [
        "## ðŸ“š Dataset Preparation and Few-Shot Example Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ae02ca8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae02ca8a",
        "outputId": "a76c53c9-3583-40fd-c74e-d3841bfe1807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded with 2000 pairs\n",
            "Sample data:\n",
            "                                              formal  \\\n",
            "0  We kindly ask that you the system update will ...   \n",
            "1  Good morning, I regret the oversight and will ...   \n",
            "2  We kindly ask that you we have identified a di...   \n",
            "3  Esteemed colleagues, I regret the oversight an...   \n",
            "4  I would appreciate it if you could we require ...   \n",
            "\n",
            "                                            informal  \n",
            "0  We'd like you to we'll update the system this ...  \n",
            "1  Morning! My bad, I'll fix it ASAP. Mind sendin...  \n",
            "2  We'd like you to we found a mistake in the dat...  \n",
            "3  Hey folks, My bad, I'll fix it ASAP. Let me kn...  \n",
            "4  I'd be grateful if you we need more info to mo...  \n",
            "After cleaning: 2000 pairs\n",
            "Training set: 1600 pairs\n",
            "Validation set: 400 pairs\n",
            "\n",
            "Selected few-shot examples:\n",
            "\n",
            "1. Informal: Hey everyone, Sorry for the late reply. Mind sending over the latest numbers? Thanks for your help! Talk soon,\n",
            "   Formal: Dear Sir or Madam, Please accept my apologies for the delay in response. Would you be so kind as to share the latest figures? Thank you for your cooperation. Best regards,\n",
            "\n",
            "2. Informal: Hey there! Sorry for the late reply. I've attached the detailed analysis. Thanks for your help! Talk soon,\n",
            "   Formal: Good afternoon, Please accept my apologies for the delay in response. Please find attached the detailed analysis. Thank you for your cooperation. Best regards,\n",
            "\n",
            "3. Informal: Hey there! Sorry for the hassle. Make sure all data entries are correct. Thanks for your help! Talk soon,\n",
            "   Formal: Good afternoon, I apologize for any inconvenience caused. Kindly ensure all data entries are accurate. Thank you for your cooperation. Best regards,\n",
            "\n",
            "4. Informal: Hey there! Sorry for the late reply. Let me know what you think about the timeline. Thanks for your help! Talk soon,\n",
            "   Formal: Good afternoon, Please accept my apologies for the delay in response. Kindly provide your feedback on the proposed timeline. Thank you for your cooperation. Best regards,\n",
            "\n",
            "5. Informal: Just so youâ€™re aware we'll do server maintenance at midnight. Any questions, just let me know.\n",
            "   Formal: It is important to highlight that the server maintenance is scheduled at midnight. Should you have any questions, please reach out.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from typing import List, Tuple, Dict\n",
        "import re\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load the valentin dataset\n",
        "dataset_path = \"valentin_dataset.csv\"\n",
        "df = pd.read_csv(dataset_path, sep=';')\n",
        "\n",
        "print(f\"Dataset loaded with {len(df)} pairs\")\n",
        "print(\"Sample data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Clean and validate the data\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean text by removing extra whitespace and normalizing\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    return re.sub(r'\\s+', ' ', str(text).strip())\n",
        "\n",
        "df['formal'] = df['formal'].apply(clean_text)\n",
        "df['informal'] = df['informal'].apply(clean_text)\n",
        "\n",
        "# Remove empty or very short entries\n",
        "df = df[(df['formal'].str.len() > 10) & (df['informal'].str.len() > 10)]\n",
        "print(f\"After cleaning: {len(df)} pairs\")\n",
        "\n",
        "# Create a validation split (80% train, 20% validation)\n",
        "train_df = df.sample(frac=0.8, random_state=42)\n",
        "val_df = df.drop(train_df.index)\n",
        "print(f\"Training set: {len(train_df)} pairs\")\n",
        "print(f\"Validation set: {len(val_df)} pairs\")\n",
        "\n",
        "def select_diverse_examples_clustering(df: pd.DataFrame, n_examples: int = 5) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Select diverse few-shot examples using K-means clustering on TF-IDF vectors\n",
        "    to ensure maximal diversity in the selected examples.\n",
        "    \"\"\"\n",
        "    # Use TF-IDF to convert text to vectors\n",
        "    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "    informal_vectors = vectorizer.fit_transform(df['informal'])\n",
        "\n",
        "    # Apply K-means clustering\n",
        "    n_clusters = min(n_examples, len(df))\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    cluster_labels = kmeans.fit_predict(informal_vectors)\n",
        "\n",
        "    # Find examples closest to each cluster center\n",
        "    selected_examples = []\n",
        "    for i in range(n_clusters):\n",
        "        # Get indices of examples in this cluster\n",
        "        cluster_indices = np.where(cluster_labels == i)[0]\n",
        "        if len(cluster_indices) == 0:\n",
        "            continue\n",
        "\n",
        "        # Find the example closest to the cluster center\n",
        "        cluster_center = kmeans.cluster_centers_[i:i+1]\n",
        "        distances = []\n",
        "        for idx in cluster_indices:\n",
        "            dist = cosine_similarity(informal_vectors[idx:idx+1], cluster_center)[0][0]\n",
        "            distances.append((idx, dist))\n",
        "\n",
        "        # Sort by distance (higher similarity = closer to center)\n",
        "        closest_idx = sorted(distances, key=lambda x: x[1], reverse=True)[0][0]\n",
        "        selected_examples.append((df.iloc[closest_idx]['informal'], df.iloc[closest_idx]['formal']))\n",
        "\n",
        "    return selected_examples\n",
        "\n",
        "# Select diverse examples for few-shot prompting using clustering\n",
        "few_shot_examples = select_diverse_examples_clustering(df, n_examples=5)\n",
        "\n",
        "print(\"\\nSelected few-shot examples:\")\n",
        "for i, (informal, formal) in enumerate(few_shot_examples, 1):\n",
        "    print(f\"\\n{i}. Informal: {informal}\")\n",
        "    print(f\"   Formal: {formal}\")\n",
        "\n",
        "# Create experiment directory with timestamp\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "experiment_dir = Path(f\"formality_translator_model_{timestamp}\")\n",
        "experiment_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Save few-shot examples for reuse\n",
        "with open(experiment_dir / \"few_shot_examples.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump([(inf, form) for inf, form in few_shot_examples], f, ensure_ascii=False, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc1261d4",
      "metadata": {
        "id": "cc1261d4"
      },
      "source": [
        "## ðŸŽ¯ Few-Shot Prompt Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "826ddea3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "826ddea3",
        "outputId": "c337e4a7-dda9-4637-864c-30ca307deccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 1596 training examples\n",
            "Created 399 validation examples\n",
            "Training data saved to formality_translator_model_20250616_200402/formality_train_dataset.jsonl\n",
            "Validation data saved to formality_translator_model_20250616_200402/formality_val_dataset.jsonl\n",
            "\n",
            "Sample few-shot prompt:\n",
            "### Task: Translate the informal text to formal text. Preserve the meaning but make the tone professional and appropriate for business or academic contexts. Only output the formal version without adding extra information. ###\n",
            "\n",
            "\n",
            "Informal: Hey everyone, Sorry for the late reply. Mind sending over the latest numbers? Thanks for your help! Talk soon,\n",
            "Formal: Dear Sir or Madam, Please accept my apologies for the delay in response. Would you be so kind as to share the latest figures? Thank you for your cooperation. Best regards,\n",
            "###\n",
            "\n",
            "Informal: Hey there! Sorry for the late reply. I've attached the detailed analysis. Thanks for your help! Talk soon,\n",
            "Formal: Good afternoon, Please accept my apologies for the delay in response. Please find attached the detailed analysis. Thank you for your cooperation. Best regards,\n",
            "###\n",
            "\n",
            "Informal: Hey there! Sorry for the hassle. Make sure all data entries are correct. Thanks for your help! Talk soon,\n",
            "Formal: Good afternoon, I apologize for any inconvenience caused. Kindly ensure all data entries are accurate. Thank you for your cooperation. Best regards,\n",
            "###\n",
            "\n",
            "Informal: Hey there! Sorry for the late reply. Let me know what you think about the timeline. Thanks for your help! Talk soon,\n",
            "Formal: Good afternoon, Please accept my apologies for the delay in response. Kindly provide your feedback on the proposed timeline. Thank you for your cooperation. Best regards,\n",
            "###\n",
            "\n",
            "Informal: Just so youâ€™re aware we'll do server maintenance at midnight. Any questions, just let me know.\n",
            "Formal: It is important to highlight that the server maintenance is scheduled at midnight. Should you have any questions, please reach out.\n",
            "###\n",
            "\n",
            "Informal: Hey, can you help me out?\n",
            "Formal:\n"
          ]
        }
      ],
      "source": [
        "def create_formality_prompt(examples: List[Tuple[str, str]], test_informal: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Create a few-shot prompt for formality translation with clear instructions\n",
        "    and delimiters to reduce hallucinations.\n",
        "\n",
        "    Args:\n",
        "        examples: List of (informal, formal) pairs for few-shot learning\n",
        "        test_informal: Optional informal sentence to translate\n",
        "\n",
        "    Returns:\n",
        "        Formatted prompt string\n",
        "    \"\"\"\n",
        "    prompt = \"\"\"### Task: Translate the informal text to formal text. Preserve the meaning but make the tone professional and appropriate for business or academic contexts. Only output the formal version without adding extra information. ###\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    for i, (informal, formal) in enumerate(examples, 1):\n",
        "        prompt += f\"\"\"\n",
        "Informal: {informal}\n",
        "Formal: {formal}\n",
        "###\n",
        "\"\"\"\n",
        "\n",
        "    if test_informal:\n",
        "        prompt += f\"\"\"\n",
        "Informal: {test_informal}\n",
        "Formal:\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "def create_training_data_with_prompts(train_df: pd.DataFrame, val_df: pd.DataFrame, few_shot_examples: List[Tuple[str, str]]) -> Tuple[List[dict], List[dict]]:\n",
        "    \"\"\"\n",
        "    Create training and validation data with few-shot context.\n",
        "    Each example includes the prompt and target formal text separately.\n",
        "    \"\"\"\n",
        "    training_data = []\n",
        "    validation_data = []\n",
        "\n",
        "    # Create a set of few-shot examples to exclude from training/validation\n",
        "    few_shot_informals = {informal for informal, _ in few_shot_examples}\n",
        "\n",
        "    # Process training data\n",
        "    for _, row in train_df.iterrows():\n",
        "        # Skip if this example is used in few-shot prompting\n",
        "        if row['informal'] in few_shot_informals:\n",
        "            continue\n",
        "\n",
        "        # Create prompt with few-shot examples and input\n",
        "        prompt = create_formality_prompt(few_shot_examples, row['informal'])\n",
        "\n",
        "        training_data.append({\n",
        "            \"prompt\": prompt,\n",
        "            \"completion\": row['formal'],\n",
        "            \"informal\": row['informal'],\n",
        "            \"formal\": row['formal']\n",
        "        })\n",
        "\n",
        "    # Process validation data\n",
        "    for _, row in val_df.iterrows():\n",
        "        # Skip if this example is used in few-shot prompting\n",
        "        if row['informal'] in few_shot_informals:\n",
        "            continue\n",
        "\n",
        "        # Create prompt with few-shot examples and input\n",
        "        prompt = create_formality_prompt(few_shot_examples, row['informal'])\n",
        "\n",
        "        validation_data.append({\n",
        "            \"prompt\": prompt,\n",
        "            \"completion\": row['formal'],\n",
        "            \"informal\": row['informal'],\n",
        "            \"formal\": row['formal']\n",
        "        })\n",
        "\n",
        "    return training_data, validation_data\n",
        "\n",
        "# Create training and validation data with few-shot prompts\n",
        "training_data, validation_data = create_training_data_with_prompts(train_df, val_df, few_shot_examples)\n",
        "print(f\"Created {len(training_data)} training examples\")\n",
        "print(f\"Created {len(validation_data)} validation examples\")\n",
        "\n",
        "# Save training and validation data to JSONL files\n",
        "train_file = experiment_dir / \"formality_train_dataset.jsonl\"\n",
        "with train_file.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    for item in training_data:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "val_file = experiment_dir / \"formality_val_dataset.jsonl\"\n",
        "with val_file.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    for item in validation_data:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"Training data saved to {train_file}\")\n",
        "print(f\"Validation data saved to {val_file}\")\n",
        "\n",
        "# Show example prompt\n",
        "sample_prompt = create_formality_prompt(few_shot_examples, \"Hey, can you help me out?\")\n",
        "print(\"\\nSample few-shot prompt:\")\n",
        "print(sample_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7a42369",
      "metadata": {
        "id": "f7a42369"
      },
      "source": [
        "## ðŸ§  Model Fine-Tuning with LoRA for Formality Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ceb3d2ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "825433cb5b4a487a8cc299ddca8fad70",
            "7d9c1ea43d0c47b599de7984e215d31b",
            "053392141e9a43778c5a0bc8dcf78dd0",
            "cf26b3630a1546059c6b9682fe4c9308",
            "d32afa71f4594213878bff7b4ac47018",
            "1d31040d623d4562b734c54fa68cee79",
            "11f230f6358644cc85013e0debd66a03",
            "3eb9eacbded6488589291a22b6d2a55f",
            "e0f57e17b24b44a693f1aa8c3499c432",
            "5d2934371eb045a2a242f65f02c1d254",
            "e1fcfce1db9e4e429e76ae5327cfbe2a",
            "ac6898adb1314518ae3a5b7413a43e13",
            "d3b45925bb2047d78ec23c387319d5da",
            "55f9d9fd22c8483a9d7b79bf46e9ad41",
            "9302506d1299493c8501a1a00f172ca7",
            "d349313678864a5897b29bec9a687375",
            "b7ccbfc893834280a8910946eeb77eb1",
            "c87179190a4f4af686c1fc39fc6a8882",
            "46bb39dff5d9440d873f1750ce9d04db",
            "5a0055dcb7f142cdb94f8be7d490a643",
            "6a6fce6d2b2d4f3c915e1c9eb7dc52a7",
            "6b8db0a31b484428a8cc0fcfa04ae183",
            "1f72b9f0e0294aa38b1225cfece743ae",
            "0a5dd5fcf4694e9a9c7a82d09637347f",
            "fa30f264c036496ea63d4efce1ea713b",
            "9504162b57e046789328b831eb5637dd",
            "faba07a0eab1470b95c6693a1aa479f6",
            "fc2f444d34a744908aa6484b13dc4ed2",
            "ea035f14de5b47f89449aca14413d932",
            "d2f9396dc8b44d159d1035a2da7672d7",
            "08fd69a06ec54d4d895432b00ade1529",
            "08ab68ea954f4427befb106e39d1b134",
            "c96915028fe247079c643c2971869bb0",
            "d8267af0a9624d3e824b43a7cf8e1123",
            "be46810390784274b758707391739cee",
            "29d3e84a56634b3b873839dbc4ae6f27",
            "a1291f326b5940b8ad083c091be80565",
            "50000590f60442a5a107b436e5184578",
            "d7ee13182cf44ad78f1d557d940877d8",
            "ed0dbf86c31a46d3886818061b532fd9",
            "f3890e8c706742cbb49ef24706dec811",
            "ba11d2274b9d4b9aa10270bd78bbdce6",
            "4c3fb3f064dd415bb0786f6f02209c76",
            "5b6b1efb82bc4d799e59fbb6c29cf29b",
            "b32dc32b2dd2432da1b2adfb18a4a4cc",
            "fb569f9fb7a74db193614b6283747cce",
            "c1469be0cdb344aba73f04b09f83eb87",
            "fff08127612b4beda2505677b85574d5",
            "92b89bd9314843aaad237c08e7aa5261",
            "b53541bfe91e4c2cadf9bc975bfce5aa",
            "1fb5da3ab4894fa48f917f5039c3cff7",
            "cc380f0cd19145cebb741dbb5eec4339",
            "c1db67f37a20484c8f8e0e736b669cae",
            "3ed20ba9f035495d8b0484b36817172c",
            "a0531d03e3664707ae16bc2fb6fa8322",
            "99aa9ca1fc30410899a995f13f117be6",
            "1ff43e21bfe94738892b49eb962289ed",
            "2b2ac848091048199c06056f485f82c9",
            "14a42497afb441fdbad18db405438df1",
            "60d659ac08344b37a4a19106c4842ccd",
            "7addd757c6644ab7a2d692b9d2386081",
            "d5c90ed874714cdd8d5f4d25c8085074",
            "601a9d31dc8b4a15a1899d01047215a3",
            "ca7cc6940c0c4258b7dfc21bc92d12f1",
            "64f49533b0124a25a1b4bb4c010a0f54",
            "8d902a1808cc48e5be0060e12a0db403",
            "5b190c46be0b405096a305faf83b3a5a",
            "6b4672d02bcb47d191029bc703bd665e",
            "71ef382cb2144f6794585051d6b4bd09",
            "776dbe11845c4c3787283463707388b0",
            "1b563632434a43388645f4d85af8b675",
            "c134ea7cb5af4238ba09810241b65bc5",
            "d8874f6f3f1941faa89a06631c5b6fb1",
            "0bc3b1e0a384491590a2d9029376f041",
            "cfbc402cd9e84df39435992e40ad9133",
            "6d394b63d1aa47979f172027a679b01e",
            "d93d809f49334e11a46edd7bab2cea1e",
            "7361f41637b3410c812a3544fa556ce7",
            "7546622054174d2eb391f912e44f26d6",
            "bfe42c90103e4c02b6998004dedb9525",
            "6e4d9acacde54a5590c0b0854d320dc1",
            "43900a9b19484aef8df9a31a1ef71dc1",
            "df0465a63a234401a52c2cf09a213351",
            "42b08478acd54178a69fc1e02750fd60",
            "4b2ce1daedbf446babcdb1452b18e471",
            "cc72c781ef6649c491b81dbd354ad5c0",
            "6e05a81bc9d14fb7b8c80e811571cdf6",
            "09d123b9978548ebaabccccd58be5733",
            "62200d040dda402580705ebaa47425e4",
            "c2f020cfc8414c71a0ae559a69947b65",
            "867249d26e4743f0b720f6db79795777",
            "0c149a6aca6b4382b922b0d20fb63b2b",
            "d3bb7e7809a14d978422f7d1511a4244",
            "3d59eb40e1964f29a798dbe34ef6a3b4",
            "56e4db855ca64e47ac081844f1d67e82",
            "5a25c5937250436685eec45f856b774b",
            "f218121b4245462788b75cd0e81dbd25",
            "e983bc0149be443a94dca866ba291379",
            "186b0b2ae90a4fab892cf613d5c3c769",
            "3148759d4b59496eb9ca21920a8dc2e7",
            "6be4cdbf9d994f6c83b286e05ff631a5",
            "48316d6848bf4b1ea4c94e333f95cc6d",
            "bfcd5f0804f64e37908c0f4329c0d27e",
            "5edc4663b9c94bff94cd3da4b16c4ab8",
            "646247fe3123495a888a9c06246edd55",
            "3842ef75165a431c9478c7fb229df75b",
            "8094656b70444969b2c455ad15b34746",
            "16defce03be9455eba4e2dcbd0f0742c",
            "0b1ab92b873b4fe6b40f7312842b313f",
            "13e0b238e6ad487d8a02e278e0b11864",
            "f60401db3fd0423b91862511c48f474c",
            "9b37c68607594284b0d6a99ebaf50349",
            "c4880610bebd4036a19c4f2c6bf8f547",
            "8ac1e706e75d47a8875ed319fc8f7ac9",
            "c2c45ad336254db28b803540021526b2",
            "7949c2ecf6dd496093521de511729dea",
            "84ad481c00e84f37949190ef74983be6",
            "c2eef878af4f494cab3aa6fa848c4e64",
            "ac0164e9bbab430cbbebe911ae9bd2ee",
            "6933b98d04fd46b1b41ba9c2080f08b5",
            "50e80d9571ee4492b2f7fa0746bd875e",
            "b52107cf662042518fc8491bdcb99d70",
            "9a607870539b4775a7179cf2039440f0",
            "0071d07cbb464ef1bf0013f1318a8667",
            "e59ebec1a1c44c3383a758362c40e3c6",
            "a48267d4a5d640f097121392c28872b5",
            "0a780120363945d2bb03df6ea7a8ca1e",
            "ea8d70c31aac4b4f96b211d1b314b88f",
            "f4ec66c3a097472daf2e2f07f153e36b",
            "dab395e58e5d443db6d0ee5c9f59a8a1",
            "5a374deff01245d0b1fe1d01c2dcdcb0",
            "1362040b90be4862ad460d865729b749",
            "8a981d98238c4df698ebf6c1f2c5a3f1",
            "f020570191604a8d9f22bce040ffa4e0",
            "eb789710462a4564bb26c5d4b25d1cd4",
            "656f9fef43ee476d97402b8bf4ca6e8a",
            "49bc9b56565e4860b04f70b0a697a70c",
            "5ebd9763f3254c7da0beec43b7338910",
            "770993eadade430c8b60ce77817e859a",
            "48b4ae3578604b4880546d302b9a8a0e",
            "35f9f43431e04a52b7420109ac42756f",
            "3064ce77a76a4036a2f8eadc170b61e7",
            "ff89dc7fb6f14a06b49ad46f09c7ceb8",
            "fa5734f48688402e8468451759015064",
            "d9b2ce4dc75f49db9941da3dd2bbe632",
            "d016126f78ec4c31853994e08f851c3a",
            "2aefb8fc5da14b548e7ed426de42fa1d",
            "86e0d3a8d7c3428bac445daf45580b83",
            "76034b03fb6846dd927bcfc7ccd0a7b5",
            "7f408cf433604ed599462bae6e72df36",
            "949f61f295684516832800eee2dad1a8",
            "de2c3ac50c0b467b84c2b232004402f0",
            "e6aab631a43f4dd6a9a2e471c5f76ac2",
            "828fc1ccb364490bb4c28c3f268c78d0",
            "648fb93194694ce2a74471b7d7945f89",
            "2670228e21ea44da965cc78a9f629853",
            "470ffd446bd84bbd8f5f3f7b05847c56",
            "fb22109ef9924dd5a94a3dbcc768648b",
            "46aff7397feb42edb37a73544aed4022",
            "ccbb7a59b7224164a32a95de49bc7d9f",
            "54b7a16c540d472884fc1f75f8a66f0d",
            "3d7736ef385647479aac7c407db26496",
            "0626eef493854f099c44610f3c8f2ab8",
            "c1f0ba937d3c4bc9bca1fa06e4e9a583",
            "b11c727bcf3c483391e839bf2ce3bbba"
          ]
        },
        "id": "ceb3d2ce",
        "outputId": "d51332df-5be9-4a59-bc87-42c5bb09915b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Using model: gpt2-medium\n",
            "Loaded 1596 training examples\n",
            "Loaded 399 validation examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "825433cb5b4a487a8cc299ddca8fad70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac6898adb1314518ae3a5b7413a43e13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f72b9f0e0294aa38b1225cfece743ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8267af0a9624d3e824b43a7cf8e1123"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b32dc32b2dd2432da1b2adfb18a4a4cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99aa9ca1fc30410899a995f13f117be6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b190c46be0b405096a305faf83b3a5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 8-bit quantization with bitsandbytes\n",
            "Model size: 363.5M parameters\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Converting train dataset to ChatML:   0%|          | 0/1596 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7361f41637b3410c812a3544fa556ce7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding EOS to train dataset:   0%|          | 0/1596 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62200d040dda402580705ebaa47425e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/1596 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3148759d4b59496eb9ca21920a8dc2e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/1596 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f60401db3fd0423b91862511c48f474c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Converting eval dataset to ChatML:   0%|          | 0/399 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b52107cf662042518fc8491bdcb99d70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding EOS to eval dataset:   0%|          | 0/399 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a981d98238c4df698ebf6c1f2c5a3f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing eval dataset:   0%|          | 0/399 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa5734f48688402e8468451759015064"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating eval dataset:   0%|          | 0/399 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "648fb93194694ce2a74471b7d7945f89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting formality translation training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 13:56, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.639700</td>\n",
              "      <td>1.410008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.545400</td>\n",
              "      <td>0.375704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.305900</td>\n",
              "      <td>0.227220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.264800</td>\n",
              "      <td>0.206285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.259700</td>\n",
              "      <td>0.203755</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete. Metrics: {'train_runtime': 838.9346, 'train_samples_per_second': 9.512, 'train_steps_per_second': 0.596, 'total_flos': 6657123042361344.0, 'train_loss': 0.7630645055770874}\n",
            "Formality translator model saved to ./formality_translator_model/best_model\n",
            "All experiment artifacts saved to ./formality_translator_model\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments\n",
        ")\n",
        "from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n",
        "from trl import SFTTrainer\n",
        "import os\n",
        "import math\n",
        "from transformers.optimization import get_scheduler\n",
        "\n",
        "# Define output directory for model checkpoints and artifacts\n",
        "base_output_dir = \"./formality_translator_model\"\n",
        "\n",
        "# Check CUDA availability and set model name\n",
        "MODEL_NAME = \"gpt2-medium\"  # Upgraded from \"gpt2\" to \"gpt2-medium\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Using model: {MODEL_NAME}\")\n",
        "\n",
        "# Load datasets from JSONL files\n",
        "def load_jsonl_dataset(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = [json.loads(line) for line in f if line.strip()]\n",
        "    return Dataset.from_list(data)\n",
        "\n",
        "train_dataset = load_jsonl_dataset(train_file)\n",
        "val_dataset = load_jsonl_dataset(val_file)\n",
        "print(f\"Loaded {len(train_dataset)} training examples\")\n",
        "print(f\"Loaded {len(val_dataset)} validation examples\")\n",
        "\n",
        "# Load tokenizer and configure\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"  # Better for causal language modeling\n",
        "\n",
        "# Configure model loading with optimized precision\n",
        "try:\n",
        "    if device == \"cuda\":\n",
        "        # Use 8-bit quantization for efficiency\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_8bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "            bnb_4bit_use_double_quant=True\n",
        "        )\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            quantization_config=bnb_config,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        model = prepare_model_for_kbit_training(model)\n",
        "        print(\"Using 8-bit quantization with bitsandbytes\")\n",
        "    else:\n",
        "        raise RuntimeError(\"Not using CUDA, falling back to regular loading\")\n",
        "except Exception as e:\n",
        "    print(f\"Quantization not available ({e}), falling back to regular model loading...\")\n",
        "    # Fallback to regular model loading without quantization\n",
        "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "    model = model.to(device)\n",
        "    print(\"Using regular model loading without quantization\")\n",
        "\n",
        "# Configure LoRA for efficient fine-tuning with improved parameters\n",
        "lora_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\"c_attn\", \"c_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "print(f\"Model size: {model.num_parameters() / 1e6:.1f}M parameters\")\n",
        "\n",
        "# Prepare the dataset for SFTTrainer (expects a 'text' field)\n",
        "def make_sft_dataset(dataset):\n",
        "    # Each item should be a dict with a 'text' field containing the prompt + completion\n",
        "    return Dataset.from_list([\n",
        "        {\"text\": f\"{item['prompt']} {item['completion']}\"} for item in dataset\n",
        "    ])\n",
        "\n",
        "sft_train_dataset = make_sft_dataset(train_dataset)\n",
        "sft_val_dataset = make_sft_dataset(val_dataset)\n",
        "\n",
        "# Calculate optimal batch size based on dataset size\n",
        "batch_size = 4 if device == \"cuda\" else 2\n",
        "gradient_accumulation_steps = max(1, 16 // batch_size)  # Target effective batch size of ~16\n",
        "\n",
        "# Improved training arguments for better performance\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=base_output_dir,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    learning_rate=2e-5,\n",
        "    lr_scheduler_type=\"cosine_with_restarts\",  # Better convergence\n",
        "    warmup_ratio=0.1,  # 10% warmup for stability\n",
        "    num_train_epochs=5,  # Reduced from 10 (faster with better settings)\n",
        "    logging_steps=25,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,\n",
        "    save_total_limit=3,  # Keep only the best 3 checkpoints\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    fp16=(device == \"cuda\"),\n",
        "    weight_decay=0.01,\n",
        "    seed=42,\n",
        "    report_to=\"none\"  # Disable wandb/tensorboard reporting\n",
        ")\n",
        "\n",
        "# SFTTrainer with improved configuration\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=sft_train_dataset,\n",
        "    eval_dataset=sft_val_dataset,\n",
        "    processing_class=tokenizer\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting formality translation training...\")\n",
        "train_result = trainer.train()\n",
        "\n",
        "# Print training metrics\n",
        "print(f\"Training complete. Metrics: {train_result.metrics}\")\n",
        "\n",
        "# Save the model and configurations\n",
        "model_path = os.path.join(base_output_dir, \"best_model\")\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "\n",
        "# Save training arguments\n",
        "with open(os.path.join(base_output_dir, \"training_args.json\"), \"w\") as f:\n",
        "    f.write(training_args.to_json_string())\n",
        "\n",
        "print(f\"Formality translator model saved to {model_path}\")\n",
        "print(f\"All experiment artifacts saved to {base_output_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c02f4a9",
      "metadata": {
        "id": "1c02f4a9"
      },
      "source": [
        "## âœ¨ Formality Translation Testing and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3ffb9c25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ffb9c25",
        "outputId": "c1410752-814a-4051-8a31-72bac33e9ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Formality Translation Results:\n",
            "\n",
            "============================================================\n",
            "\n",
            "Input (Informal): Hey everyone, My bad, I'll fix it ASAP. Can you take a look at the attached doc? Really appreciate the help. Cheers,\n",
            "Expected (Formal): Dear Sir or Madam, I regret the oversight and will correct it promptly. I would appreciate your assistance in reviewing the attached document. Your support is greatly appreciated. Yours faithfully,\n",
            "Generated (Formal): You should review our documentation carefully.\n",
            "----------------------------------------\n",
            "\n",
            "Input (Informal): Don't forget that love to hear what you think about the draft. Chat soon!\n",
            "Expected (Formal): Allow me to remind you that your feedback on the draft is greatly appreciated. I look forward to your prompt response.\n",
            "Generated (Formal): We appreciate your input regarding the preliminary report.\n",
            "----------------------------------------\n",
            "\n",
            "Input (Informal): Hey folks, Sorry for the hassle. Can you tell me if youâ€™re free for the meeting? Can't wait to hear back from you! Talk soon,\n",
            "Expected (Formal): Esteemed colleagues, I apologize for any inconvenience caused. Please confirm your availability for the meeting. I look forward to your response. Best regards,\n",
            "Generated (Formal): The Department of Finance will initiate a conference call between 12 noon and 2pm.\n",
            "----------------------------------------\n",
            "\n",
            "Input (Informal): You gotta we'll do server maintenance at midnight. Chat soon!\n",
            "Expected (Formal): It is essential that you the server maintenance is scheduled at midnight. I look forward to your prompt response.\n",
            "Generated (Formal): We will follow up with a request for support during the downtime period.\n",
            "----------------------------------------\n",
            "\n",
            "Input (Informal): Hey everyone, My bad, I'll fix it ASAP. I've attached the detailed analysis. Thanks for jumping on this so quickly. Cheers,\n",
            "Expected (Formal): Dear Sir or Madam, I regret the oversight and will correct it promptly. Please find attached the detailed analysis. I appreciate your prompt attention to this matter. Yours faithfully,\n",
            "Generated (Formal): The highlighted paragraph provides a thorough explanation of the impact of the action. Your attention is greatly appreciated.\n",
            "----------------------------------------\n",
            "\n",
            "ðŸ“ Example Translations with Standard Examples:\n",
            "â€¢ Hey, what's up? â†’ We'd appreciate it if you could check our status online.\n",
            "â€¢ Can you help me out with this thing? â†’ No problemo, it's a short document format only really interested in getting input from stakeholders involved in project management.\n",
            "â€¢ Thanks a bunch for your help! â†’ We appreciate the prompt attention required to address this issue quickly.\n",
            "â€¢ I'll get back to you ASAP. â†’ All righty then, it's time â›ï¸âšªTalk now\n",
            "â€¢ Let me know if you need anything. â†’ All right guys, it's time againâ€”letÊ¼s get this thing started!\n",
            "\n",
            "ðŸ“ Example Translations with Dynamic Example Selection:\n",
            "â€¢ Hey, what's up? â†’ We'd appreciate it if you could check our status online.\n",
            "â€¢ Can you help me out with this thing? â†’ No problemo, it's a short document format only really interested in getting input from stakeholders involved in project management.\n",
            "â€¢ Thanks a bunch for your help! â†’ We appreciate the prompt attention required to address this issue quickly.\n",
            "â€¢ I'll get back to you ASAP. â†’ All righty then, it's time â›ï¸âšªTalk now\n",
            "â€¢ Let me know if you need anything. â†’ All right guys, it's time againâ€”letÊ¼s get this thing started!\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import random\n",
        "import re\n",
        "from functools import lru_cache  # Add caching for efficiency\n",
        "\n",
        "# Load the fine-tuned formality translator\n",
        "model_path = os.path.join(base_output_dir, \"best_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Load model with optimized settings for inference\n",
        "device_map = \"auto\" if torch.cuda.is_available() else None\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    device_map=device_map,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        ")\n",
        "\n",
        "# Create a text generation pipeline with optimized decoding parameters\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=device_map\n",
        ")\n",
        "\n",
        "@lru_cache(maxsize=128)  # Cache results for repeated inputs\n",
        "def translate_to_formal(informal_text: str, few_shot_examples: tuple) -> str:\n",
        "    \"\"\"\n",
        "    Translate informal text to formal using few-shot prompting with improved decoding.\n",
        "    Uses caching for efficiency on repeated inputs.\n",
        "\n",
        "    Args:\n",
        "        informal_text: The informal text to translate\n",
        "        few_shot_examples: Tuple of (informal, formal) example pairs (converted from list for cache)\n",
        "\n",
        "    Returns:\n",
        "        The formal translation\n",
        "    \"\"\"\n",
        "    # Convert tuple back to list for processing\n",
        "    examples = list(few_shot_examples)\n",
        "\n",
        "    # Create prompt with few-shot examples\n",
        "    prompt = create_formality_prompt(examples, informal_text)\n",
        "\n",
        "    # Generate with optimized decoding parameters\n",
        "    output = generator(\n",
        "        prompt,\n",
        "        max_new_tokens=100,\n",
        "        do_sample=True,\n",
        "        temperature=0.4,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.2,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    generated_text = output[0][\"generated_text\"]\n",
        "\n",
        "    # Extract only the formal translation (after the last \"Formal:\")\n",
        "    if \"Formal:\" in generated_text:\n",
        "        formal_part = generated_text.split(\"Formal:\")[-1].strip()\n",
        "    else:\n",
        "        # Fallback if format is unexpected\n",
        "        formal_part = generated_text.split(informal_text)[-1].strip()\n",
        "\n",
        "    # Improved post-processing with additional cleanup\n",
        "    # 1. Remove any trailing ### markers or other artifacts\n",
        "    formal_part = re.sub(r'###.*$', '', formal_part)\n",
        "\n",
        "    # 2. Remove any informal prefixes that might have been copied\n",
        "    informal_lower = informal_text.lower()\n",
        "    if formal_part.lower().startswith(informal_lower):\n",
        "        formal_part = formal_part[len(informal_text):].strip()\n",
        "\n",
        "    # 3. Split by newlines and punctuation to get first complete sentence/phrase\n",
        "    lines = formal_part.split('\\n')\n",
        "    first_line = lines[0].strip() if lines else \"\"\n",
        "\n",
        "    # 4. Make sure it ends with proper punctuation\n",
        "    if first_line and not any(first_line.endswith(p) for p in '.!?'):\n",
        "        # Find the first sentence ending\n",
        "        sentence_match = re.search(r'^(.*?[.!?])', first_line)\n",
        "        if sentence_match:\n",
        "            first_line = sentence_match.group(1).strip()\n",
        "\n",
        "    return first_line.strip()\n",
        "\n",
        "# Function to get most similar few-shot examples for dynamic prompting\n",
        "def get_similar_examples(informal_text: str, examples_pool: List[Tuple[str, str]], n: int = 5) -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Select the most similar examples from a pool for dynamic few-shot prompting\n",
        "    \"\"\"\n",
        "    if len(examples_pool) <= n:\n",
        "        return examples_pool\n",
        "\n",
        "    # Create vectors\n",
        "    texts = [ex[0] for ex in examples_pool] + [informal_text]\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform(texts)\n",
        "\n",
        "    # Calculate similarities\n",
        "    query_vector = vectors[-1]\n",
        "    example_vectors = vectors[:-1]\n",
        "    similarities = cosine_similarity(query_vector, example_vectors)[0]\n",
        "\n",
        "    # Get indices of most similar examples\n",
        "    top_indices = similarities.argsort()[-n:][::-1]\n",
        "\n",
        "    # Return most similar examples\n",
        "    return [examples_pool[i] for i in top_indices]\n",
        "\n",
        "# Test with examples from the validation set\n",
        "test_examples = val_df.sample(5, random_state=42)\n",
        "\n",
        "print(\"ðŸŽ¯ Formality Translation Results:\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for idx, row in test_examples.iterrows():\n",
        "    informal_input = row['informal']\n",
        "    expected_formal = row['formal']\n",
        "\n",
        "    # Get dynamically selected examples for this specific input\n",
        "    dynamic_examples = get_similar_examples(informal_input, few_shot_examples)\n",
        "\n",
        "    # Convert examples list to tuple for caching\n",
        "    dynamic_examples_tuple = tuple((inf, form) for inf, form in dynamic_examples)\n",
        "\n",
        "    # Generate translation using dynamic examples\n",
        "    predicted_formal = translate_to_formal(informal_input, dynamic_examples_tuple)\n",
        "\n",
        "    print(f\"\\nInput (Informal): {informal_input}\")\n",
        "    print(f\"Expected (Formal): {expected_formal}\")\n",
        "    print(f\"Generated (Formal): {predicted_formal}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Interactive testing function with dynamic prompting\n",
        "def interactive_formality_test():\n",
        "    \"\"\"\n",
        "    Interactive function to test formality translation with user input.\n",
        "    Uses dynamic example selection based on input text.\n",
        "    \"\"\"\n",
        "    print(\"\\nðŸ”„ Interactive Formality Translation Test\")\n",
        "    print(\"Enter informal sentences to see their formal translations.\")\n",
        "    print(\"Type 'quit' to exit.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Informal sentence: \").strip()\n",
        "\n",
        "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if not user_input:\n",
        "            continue\n",
        "\n",
        "        # Select the most relevant examples for this input\n",
        "        dynamic_examples = get_similar_examples(user_input, few_shot_examples)\n",
        "        dynamic_examples_tuple = tuple((inf, form) for inf, form in dynamic_examples)\n",
        "\n",
        "        # Translate with dynamic examples\n",
        "        formal_output = translate_to_formal(user_input, dynamic_examples_tuple)\n",
        "        print(f\"Formal translation: {formal_output}\\n\")\n",
        "\n",
        "# Example translations with standard examples\n",
        "example_informal_sentences = [\n",
        "    \"Hey, what's up?\",\n",
        "    \"Can you help me out with this thing?\",\n",
        "    \"Thanks a bunch for your help!\",\n",
        "    \"I'll get back to you ASAP.\",\n",
        "    \"Let me know if you need anything.\"\n",
        "]\n",
        "\n",
        "print(\"\\nðŸ“ Example Translations with Standard Examples:\")\n",
        "few_shot_examples_tuple = tuple((inf, form) for inf, form in few_shot_examples)\n",
        "for informal in example_informal_sentences:\n",
        "    formal = translate_to_formal(informal, few_shot_examples_tuple)\n",
        "    print(f\"â€¢ {informal} â†’ {formal}\")\n",
        "\n",
        "# Example translations with dynamic example selection\n",
        "print(\"\\nðŸ“ Example Translations with Dynamic Example Selection:\")\n",
        "for informal in example_informal_sentences:\n",
        "    # Select the most relevant examples for this specific input\n",
        "    dynamic_examples = get_similar_examples(informal, few_shot_examples)\n",
        "    dynamic_examples_tuple = tuple((inf, form) for inf, form in dynamic_examples)\n",
        "    formal = translate_to_formal(informal, dynamic_examples_tuple)\n",
        "    print(f\"â€¢ {informal} â†’ {formal}\")\n",
        "\n",
        "# Run interactive test (uncomment to use)\n",
        "# interactive_formality_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "WZJpKSfwnbcj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WZJpKSfwnbcj",
        "outputId": "bc15a905-1af7-46f8-da4f-02dd76d0a9e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nshutil.make_archive(\"formality_translator_model\", \\'zip\\', base_output_dir)\\nfiles.download(\"formality_translator_model.zip\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Zip the model directory and download to local dev PC\n",
        "\n",
        "shutil.make_archive(\"formality_translator_model\", 'zip', base_output_dir)\n",
        "files.download(\"formality_translator_model.zip\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf9b801f",
      "metadata": {
        "id": "bf9b801f"
      },
      "source": [
        "## ðŸ“Š Evaluation Metrics and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9d859cb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9d859cb5",
        "outputId": "90606a85-9643-4b35-fbd1-b469d0e501a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” Running evaluation with standard fixed prompts:\n",
            "Evaluating formality translation on 20 examples...\n",
            "\n",
            "ðŸ“Š Evaluation Results (n=20):\n",
            "==================================================\n",
            "Average BLEU Score: 0.016\n",
            "Average METEOR Score: 0.085\n",
            "Average Formal Indicators Added: -2.30\n",
            "Average Informal Indicators Removed: 2.35\n",
            "Average Formality Score: 0.03\n",
            "Average Output/Input Length Ratio: 0.94\n",
            "\n",
            "ðŸ“ Sample Results:\n",
            "\n",
            "Example 1:\n",
            "Informal: Hey everyone, My bad, I'll fix it ASAP. Can you take a look at the attached doc? Really appreciate the help. Cheers,\n",
            "Reference: Dear Sir or Madam, I regret the oversight and will correct it promptly. I would appreciate your assistance in reviewing the attached document. Your support is greatly appreciated. Yours faithfully,\n",
            "Generated: You should review our documentation carefully.\n",
            "BLEU: 0.001, METEOR: 0.000\n",
            "Formality Score: -1.00\n",
            "\n",
            "Example 2:\n",
            "Informal: Don't forget that love to hear what you think about the draft. Chat soon!\n",
            "Reference: Allow me to remind you that your feedback on the draft is greatly appreciated. I look forward to your prompt response.\n",
            "Generated: We appreciate your input regarding the preliminary report.\n",
            "BLEU: 0.007, METEOR: 0.000\n",
            "Formality Score: 1.00\n",
            "\n",
            "Example 3:\n",
            "Informal: Hey folks, Sorry for the hassle. Can you tell me if youâ€™re free for the meeting? Can't wait to hear back from you! Talk soon,\n",
            "Reference: Esteemed colleagues, I apologize for any inconvenience caused. Please confirm your availability for the meeting. I look forward to your response. Best regards,\n",
            "Generated: The Department of Finance will initiate a conference call between 12 noon and 2pm.\n",
            "BLEU: 0.008, METEOR: 0.000\n",
            "Formality Score: 0.00\n",
            "\n",
            "Example 4:\n",
            "Informal: You gotta we'll do server maintenance at midnight. Chat soon!\n",
            "Reference: It is essential that you the server maintenance is scheduled at midnight. I look forward to your prompt response.\n",
            "Generated: We will follow up with a request for support during the downtime period.\n",
            "BLEU: 0.013, METEOR: 0.049\n",
            "Formality Score: 1.00\n",
            "\n",
            "Example 5:\n",
            "Informal: Hey everyone, My bad, I'll fix it ASAP. I've attached the detailed analysis. Thanks for jumping on this so quickly. Cheers,\n",
            "Reference: Dear Sir or Madam, I regret the oversight and will correct it promptly. Please find attached the detailed analysis. I appreciate your prompt attention to this matter. Yours faithfully,\n",
            "Generated: The highlighted paragraph provides a thorough explanation of the impact of the action. Your attention is greatly appreciated.\n",
            "BLEU: 0.010, METEOR: 0.000\n",
            "Formality Score: 0.50\n",
            "\n",
            "ðŸ” Running evaluation with dynamic similar-example prompts:\n",
            "Evaluating formality translation on 20 examples...\n",
            "\n",
            "ðŸ“Š Evaluation Results (n=20):\n",
            "==================================================\n",
            "Average BLEU Score: 0.016\n",
            "Average METEOR Score: 0.101\n",
            "Average Formal Indicators Added: -2.30\n",
            "Average Informal Indicators Removed: 2.35\n",
            "Average Formality Score: 0.03\n",
            "Average Output/Input Length Ratio: 0.94\n",
            "\n",
            "ðŸ“ Sample Results:\n",
            "\n",
            "Example 1:\n",
            "Informal: Hey everyone, My bad, I'll fix it ASAP. Can you take a look at the attached doc? Really appreciate the help. Cheers,\n",
            "Reference: Dear Sir or Madam, I regret the oversight and will correct it promptly. I would appreciate your assistance in reviewing the attached document. Your support is greatly appreciated. Yours faithfully,\n",
            "Generated: You should review our documentation carefully.\n",
            "BLEU: 0.001, METEOR: 0.047\n",
            "Formality Score: -1.00\n",
            "\n",
            "Example 2:\n",
            "Informal: Don't forget that love to hear what you think about the draft. Chat soon!\n",
            "Reference: Allow me to remind you that your feedback on the draft is greatly appreciated. I look forward to your prompt response.\n",
            "Generated: We appreciate your input regarding the preliminary report.\n",
            "BLEU: 0.007, METEOR: 0.093\n",
            "Formality Score: 1.00\n",
            "\n",
            "Example 3:\n",
            "Informal: Hey folks, Sorry for the hassle. Can you tell me if youâ€™re free for the meeting? Can't wait to hear back from you! Talk soon,\n",
            "Reference: Esteemed colleagues, I apologize for any inconvenience caused. Please confirm your availability for the meeting. I look forward to your response. Best regards,\n",
            "Generated: The Department of Finance will initiate a conference call between 12 noon and 2pm.\n",
            "BLEU: 0.008, METEOR: 0.037\n",
            "Formality Score: 0.00\n",
            "\n",
            "Example 4:\n",
            "Informal: You gotta we'll do server maintenance at midnight. Chat soon!\n",
            "Reference: It is essential that you the server maintenance is scheduled at midnight. I look forward to your prompt response.\n",
            "Generated: We will follow up with a request for support during the downtime period.\n",
            "BLEU: 0.013, METEOR: 0.049\n",
            "Formality Score: 1.00\n",
            "\n",
            "Example 5:\n",
            "Informal: Hey everyone, My bad, I'll fix it ASAP. I've attached the detailed analysis. Thanks for jumping on this so quickly. Cheers,\n",
            "Reference: Dear Sir or Madam, I regret the oversight and will correct it promptly. Please find attached the detailed analysis. I appreciate your prompt attention to this matter. Yours faithfully,\n",
            "Generated: The highlighted paragraph provides a thorough explanation of the impact of the action. Your attention is greatly appreciated.\n",
            "BLEU: 0.010, METEOR: 0.107\n",
            "Formality Score: 0.50\n",
            "\n",
            "ðŸŽ¯ Model Performance Comparison:\n",
            "==================================================\n",
            "Metric               | Standard Prompts | Dynamic Prompts | Difference\n",
            "--------------------------------------------------\n",
            "BLEU Score           | 0.016            | 0.016            | 0.000\n",
            "METEOR Score         | 0.085            | 0.101            | 0.016\n",
            "Formality Score      | 0.03             | 0.03             | 0.00\n",
            "Output/Input Ratio   | 0.94             | 0.94             | 0.00\n",
            "\n",
            "âœ… Evaluation complete! Results saved to evaluation_results.json and evaluation metrics plots.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from collections import Counter\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from concurrent.futures import ThreadPoolExecutor  # For parallel processing\n",
        "\n",
        "# Download required NLTK data only if not already available\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except LookupError:\n",
        "    nltk.download('wordnet')\n",
        "    nltk.download('omw-1.4')  # Open Multilingual WordNet\n",
        "\n",
        "# Download the missing 'punkt_tab' resource\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# Enhanced formal/informal indicators based on linguistic features\n",
        "formal_indicators = {\n",
        "    'lexical': [\n",
        "        'please', 'kindly', 'would', 'could', 'sincerely', 'respectfully',\n",
        "        'appreciate', 'grateful', 'thank you', 'regards', 'esteemed',\n",
        "        'certainly', 'however', 'therefore', 'consequently', 'furthermore'\n",
        "    ],\n",
        "    'phrases': [\n",
        "        'I would like to', 'I am writing to', 'Please be advised',\n",
        "        'I would appreciate', 'We kindly ask', 'To whom it may concern',\n",
        "        'I am pleased to', 'I regret to inform', 'I look forward to'\n",
        "    ],\n",
        "    'punctuation': ['.', ',', ';', ':'],\n",
        "}\n",
        "\n",
        "informal_indicators = {\n",
        "    'lexical': [\n",
        "        'hey', 'hi', 'thanks', 'gonna', 'wanna', 'yeah', 'ok', 'cool',\n",
        "        'asap', 'btw', 'lol', 'omg', 'fyi', 'u', 'r', 'ur', 'ya', 'yep'\n",
        "    ],\n",
        "    'contractions': [\n",
        "        \"'ll\", \"'d\", \"n't\", \"'re\", \"'ve\", \"'s\", \"i'm\", \"dunno\", \"kinda\", \"sorta\"\n",
        "    ],\n",
        "    'phrases': [\n",
        "        'check out', 'what\\'s up', 'hit me up', 'touch base',\n",
        "        'heads up', 'just wanted to', 'let me know', 'sounds good'\n",
        "    ],\n",
        "    'punctuation': ['!', '!!', '...']\n",
        "}\n",
        "\n",
        "def evaluate_formality_translation(test_size: int = 30, use_dynamic_prompts: bool = True):\n",
        "    \"\"\"\n",
        "    Evaluate the formality translation model using multiple metrics.\n",
        "\n",
        "    Args:\n",
        "        test_size: Number of examples to test\n",
        "        use_dynamic_prompts: Whether to use dynamically selected examples\n",
        "                            based on input similarity\n",
        "    \"\"\"\n",
        "    # Select test examples from validation set\n",
        "    test_df = val_df.sample(min(test_size, len(val_df)), random_state=42)\n",
        "\n",
        "    predictions = []\n",
        "    references = []\n",
        "    informal_inputs = []\n",
        "\n",
        "    print(f\"Evaluating formality translation on {len(test_df)} examples...\")\n",
        "\n",
        "    # Setup metrics collection\n",
        "    bleu_scores = []\n",
        "    meteor_scores = []\n",
        "    formal_gains = []\n",
        "    informal_reductions = []\n",
        "    output_lengths = []\n",
        "\n",
        "    def process_example(row):\n",
        "        \"\"\"Process a single evaluation example for parallel execution\"\"\"\n",
        "        informal_input = row['informal']\n",
        "        expected_formal = row['formal']\n",
        "\n",
        "        # Get examples for prompting (either fixed or dynamic)\n",
        "        if use_dynamic_prompts:\n",
        "            selected_examples = get_similar_examples(informal_input, few_shot_examples)\n",
        "        else:\n",
        "            selected_examples = few_shot_examples\n",
        "\n",
        "        # Convert to tuple for caching\n",
        "        examples_tuple = tuple((inf, form) for inf, form in selected_examples)\n",
        "\n",
        "        # Generate formal translation\n",
        "        predicted_formal = translate_to_formal(informal_input, examples_tuple)\n",
        "\n",
        "        # Calculate BLEU score\n",
        "        smoothie = SmoothingFunction().method4\n",
        "        pred_tokens = nltk.word_tokenize(predicted_formal.lower())\n",
        "        ref_tokens = nltk.word_tokenize(expected_formal.lower())\n",
        "        bleu = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoothie)\n",
        "\n",
        "        # Calculate METEOR score\n",
        "        try:\n",
        "            meteor = meteor_score([ref_tokens], pred_tokens)\n",
        "        except:\n",
        "            meteor = 0\n",
        "\n",
        "        # Analyze formality indicators\n",
        "        def count_indicators_by_category(text, indicators_dict):\n",
        "            text_lower = text.lower()\n",
        "            counts = {}\n",
        "\n",
        "            for category, indicators in indicators_dict.items():\n",
        "                if category == 'punctuation':\n",
        "                    # Count punctuation marks\n",
        "                    counts[category] = sum(text.count(p) for p in indicators)\n",
        "                else:\n",
        "                    # Count occurrences of words/phrases\n",
        "                    counts[category] = sum(1 for indicator in indicators\n",
        "                                        if re.search(rf'\\b{re.escape(indicator)}\\b', text_lower))\n",
        "\n",
        "            # Total count across all categories\n",
        "            counts['total'] = sum(counts.values())\n",
        "            return counts\n",
        "\n",
        "        # Count formal and informal indicators\n",
        "        formal_counts_pred = count_indicators_by_category(predicted_formal, formal_indicators)\n",
        "        formal_counts_input = count_indicators_by_category(informal_input, formal_indicators)\n",
        "\n",
        "        informal_counts_pred = count_indicators_by_category(predicted_formal, informal_indicators)\n",
        "        informal_counts_input = count_indicators_by_category(informal_input, informal_indicators)\n",
        "\n",
        "        # Calculate formality changes\n",
        "        formal_gain = formal_counts_pred['total'] - formal_counts_input['total']\n",
        "        informal_reduction = informal_counts_input['total'] - informal_counts_pred['total']\n",
        "\n",
        "        # Calculate length ratio\n",
        "        length_ratio = len(predicted_formal) / len(informal_input)\n",
        "\n",
        "        return {\n",
        "            'informal': informal_input,\n",
        "            'reference': expected_formal,\n",
        "            'prediction': predicted_formal,\n",
        "            'bleu': bleu,\n",
        "            'meteor': meteor,\n",
        "            'formal_gain': formal_gain,\n",
        "            'informal_reduction': informal_reduction,\n",
        "            'length_ratio': length_ratio\n",
        "        }\n",
        "\n",
        "    # Process evaluations in parallel\n",
        "    with ThreadPoolExecutor(max_workers=min(4, os.cpu_count() or 1)) as executor:\n",
        "        results = list(executor.map(process_example, [row for _, row in test_df.iterrows()]))\n",
        "\n",
        "    # Collect results\n",
        "    for result in results:\n",
        "        informal_inputs.append(result['informal'])\n",
        "        references.append(result['reference'])\n",
        "        predictions.append(result['prediction'])\n",
        "        bleu_scores.append(result['bleu'])\n",
        "        meteor_scores.append(result['meteor'])\n",
        "        formal_gains.append(result['formal_gain'])\n",
        "        informal_reductions.append(result['informal_reduction'])\n",
        "        output_lengths.append(result['length_ratio'])\n",
        "\n",
        "    # Calculate summary metrics\n",
        "    avg_bleu = np.mean(bleu_scores)\n",
        "    avg_meteor = np.mean(meteor_scores)\n",
        "    avg_formal_gain = np.mean(formal_gains)\n",
        "    avg_informal_reduction = np.mean(informal_reductions)\n",
        "    avg_length_ratio = np.mean(output_lengths)\n",
        "\n",
        "    # Calculate formality improvement score (combined metric)\n",
        "    formality_scores = [(gain + red) / 2 for gain, red in zip(formal_gains, informal_reductions)]\n",
        "    avg_formality_score = np.mean(formality_scores)\n",
        "\n",
        "    # Print detailed evaluation results\n",
        "    print(f\"\\nðŸ“Š Evaluation Results (n={len(test_df)}):\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Average BLEU Score: {avg_bleu:.3f}\")\n",
        "    print(f\"Average METEOR Score: {avg_meteor:.3f}\")\n",
        "    print(f\"Average Formal Indicators Added: {avg_formal_gain:.2f}\")\n",
        "    print(f\"Average Informal Indicators Removed: {avg_informal_reduction:.2f}\")\n",
        "    print(f\"Average Formality Score: {avg_formality_score:.2f}\")\n",
        "    print(f\"Average Output/Input Length Ratio: {avg_length_ratio:.2f}\")\n",
        "\n",
        "    # Show some example results\n",
        "    print(f\"\\nðŸ“ Sample Results:\")\n",
        "    for i in range(min(5, len(predictions))):\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(f\"Informal: {informal_inputs[i]}\")\n",
        "        print(f\"Reference: {references[i]}\")\n",
        "        print(f\"Generated: {predictions[i]}\")\n",
        "        print(f\"BLEU: {bleu_scores[i]:.3f}, METEOR: {meteor_scores[i]:.3f}\")\n",
        "        print(f\"Formality Score: {formality_scores[i]:.2f}\")\n",
        "\n",
        "    # Visualize evaluation metrics with improved plots\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.style.use('ggplot')  # Use a more modern style\n",
        "\n",
        "    # Plot BLEU scores\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.hist(bleu_scores, bins=10, alpha=0.7, color='royalblue', edgecolor='black')\n",
        "    plt.axvline(avg_bleu, color='crimson', linestyle='dashed', linewidth=2)\n",
        "    plt.title(f'BLEU Scores (avg={avg_bleu:.3f})', fontsize=12, fontweight='bold')\n",
        "    plt.xlabel('BLEU Score', fontsize=10)\n",
        "    plt.ylabel('Count', fontsize=10)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Plot formal gains vs informal reductions\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.scatter(formal_gains, informal_reductions, alpha=0.7, color='forestgreen', edgecolor='black')\n",
        "    plt.axhline(0, color='black', linestyle=':', linewidth=1)\n",
        "    plt.axvline(0, color='black', linestyle=':', linewidth=1)\n",
        "    plt.title('Formality Transformation', fontsize=12, fontweight='bold')\n",
        "    plt.xlabel('Formal Indicators Added', fontsize=10)\n",
        "    plt.ylabel('Informal Indicators Removed', fontsize=10)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Plot combined formality scores\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.hist(formality_scores, bins=10, alpha=0.7, color='darkorange', edgecolor='black')\n",
        "    plt.axvline(avg_formality_score, color='crimson', linestyle='dashed', linewidth=2)\n",
        "    plt.title(f'Formality Scores (avg={avg_formality_score:.2f})', fontsize=12, fontweight='bold')\n",
        "    plt.xlabel('Formality Score', fontsize=10)\n",
        "    plt.ylabel('Count', fontsize=10)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Plot BLEU vs formality score\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.scatter(bleu_scores, formality_scores, alpha=0.7, color='rebeccapurple', edgecolor='black')\n",
        "    plt.title('BLEU vs Formality Score', fontsize=12, fontweight='bold')\n",
        "    plt.xlabel('BLEU Score', fontsize=10)\n",
        "    plt.ylabel('Formality Score', fontsize=10)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(base_output_dir, 'evaluation_metrics.png'), dpi=300)\n",
        "\n",
        "    # Save detailed evaluation results\n",
        "    eval_results = {\n",
        "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        'test_size': len(test_df),\n",
        "        'metrics': {\n",
        "            'bleu': {\n",
        "                'individual': bleu_scores,\n",
        "                'average': avg_bleu\n",
        "            },\n",
        "            'meteor': {\n",
        "                'individual': meteor_scores,\n",
        "                'average': avg_meteor\n",
        "            },\n",
        "            'formality': {\n",
        "                'formal_gains': formal_gains,\n",
        "                'informal_reductions': informal_reductions,\n",
        "                'avg_formal_gain': avg_formal_gain,\n",
        "                'avg_informal_reduction': avg_informal_reduction,\n",
        "                'formality_scores': formality_scores,\n",
        "                'avg_formality_score': avg_formality_score\n",
        "            },\n",
        "            'length': {\n",
        "                'ratios': output_lengths,\n",
        "                'average': avg_length_ratio\n",
        "            }\n",
        "        },\n",
        "        'examples': [\n",
        "            {\n",
        "                'informal': inf,\n",
        "                'reference': ref,\n",
        "                'prediction': pred,\n",
        "                'bleu': bleu,\n",
        "                'formality_score': form_score\n",
        "            }\n",
        "            for inf, ref, pred, bleu, form_score in zip(\n",
        "                informal_inputs[:10], references[:10], predictions[:10],\n",
        "                bleu_scores[:10], formality_scores[:10]\n",
        "            )\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Save evaluation results to JSON\n",
        "    with open(os.path.join(base_output_dir, 'evaluation_results.json'), 'w') as f:\n",
        "        json.dump(eval_results, f, indent=2)\n",
        "\n",
        "    return eval_results\n",
        "\n",
        "# Run evaluations with both standard and dynamic prompting\n",
        "print(\"\\nðŸ” Running evaluation with standard fixed prompts:\")\n",
        "standard_results = evaluate_formality_translation(test_size=20, use_dynamic_prompts=False)\n",
        "\n",
        "print(\"\\nðŸ” Running evaluation with dynamic similar-example prompts:\")\n",
        "dynamic_results = evaluate_formality_translation(test_size=20, use_dynamic_prompts=True)\n",
        "\n",
        "# Compare results with improved comparison\n",
        "print(f\"\\nðŸŽ¯ Model Performance Comparison:\")\n",
        "print(\"=\"*50)\n",
        "print(\"Metric               | Standard Prompts | Dynamic Prompts | Difference\")\n",
        "print(\"-\"*50)\n",
        "print(f\"BLEU Score           | {standard_results['metrics']['bleu']['average']:.3f}            | {dynamic_results['metrics']['bleu']['average']:.3f}            | {dynamic_results['metrics']['bleu']['average'] - standard_results['metrics']['bleu']['average']:.3f}\")\n",
        "print(f\"METEOR Score         | {standard_results['metrics']['meteor']['average']:.3f}            | {dynamic_results['metrics']['meteor']['average']:.3f}            | {dynamic_results['metrics']['meteor']['average'] - standard_results['metrics']['meteor']['average']:.3f}\")\n",
        "print(f\"Formality Score      | {standard_results['metrics']['formality']['avg_formality_score']:.2f}             | {dynamic_results['metrics']['formality']['avg_formality_score']:.2f}             | {dynamic_results['metrics']['formality']['avg_formality_score'] - standard_results['metrics']['formality']['avg_formality_score']:.2f}\")\n",
        "print(f\"Output/Input Ratio   | {standard_results['metrics']['length']['average']:.2f}             | {dynamic_results['metrics']['length']['average']:.2f}             | {dynamic_results['metrics']['length']['average'] - standard_results['metrics']['length']['average']:.2f}\")\n",
        "\n",
        "# Create and save comparison chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "metrics = ['BLEU', 'METEOR', 'Formality', 'Length Ratio']\n",
        "standard_values = [\n",
        "    standard_results['metrics']['bleu']['average'],\n",
        "    standard_results['metrics']['meteor']['average'],\n",
        "    standard_results['metrics']['formality']['avg_formality_score'],\n",
        "    standard_results['metrics']['length']['average']\n",
        "]\n",
        "dynamic_values = [\n",
        "    dynamic_results['metrics']['bleu']['average'],\n",
        "    dynamic_results['metrics']['meteor']['average'],\n",
        "    dynamic_results['metrics']['formality']['avg_formality_score'],\n",
        "    dynamic_results['metrics']['length']['average']\n",
        "]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "rects1 = ax.bar(x - width/2, standard_values, width, label='Standard Prompts', color='royalblue', alpha=0.7, edgecolor='black')\n",
        "rects2 = ax.bar(x + width/2, dynamic_values, width, label='Dynamic Prompts', color='darkorange', alpha=0.7, edgecolor='black')\n",
        "\n",
        "ax.set_title('Comparison of Prompting Strategies', fontsize=16, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics, fontsize=12)\n",
        "ax.legend(fontsize=12)\n",
        "ax.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Add value labels above bars\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.2f}',\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom',\n",
        "                    fontsize=10, fontweight='bold')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(base_output_dir, 'prompting_strategy_comparison.png'), dpi=300)\n",
        "\n",
        "print(\"\\nâœ… Evaluation complete! Results saved to evaluation_results.json and evaluation metrics plots.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f13421c",
      "metadata": {
        "id": "0f13421c"
      },
      "source": [
        "# ðŸ“ Summary of Improvements\n",
        "\n",
        "This notebook has been enhanced with several key improvements to the original formality translation model:\n",
        "\n",
        "## 1. Smarter Training Implementation\n",
        "- **Dataset Handling**: Added proper train/validation split (80/20)\n",
        "- **Resource Utilization**: Increased batch size with gradient accumulation steps\n",
        "- **Model Architecture**: Upgraded from GPT-2 base to GPT-2 medium for better capacity\n",
        "- **Training Stability**: Implemented early stopping, lower learning rate, and warmup\n",
        "- **Hyperparameters**: Enhanced LoRA configuration with increased rank (r=32) and alpha (64)\n",
        "- **Mixed Precision**: Using FP16 for faster training on CUDA devices\n",
        "\n",
        "## 2. Reduced Hallucinations\n",
        "- **Prompt Engineering**: Added clearer instructions and task delimiters\n",
        "- **Decoding Strategy**: Optimized temperature (0.4), top_k (50), and top_p (0.95) values\n",
        "- **Post-processing**: Improved extraction of formal responses with regex filtering\n",
        "- **Repetition Penalty**: Increased to 1.2 to prevent text loops\n",
        "\n",
        "## 3. Smarter Few-Shot Prompting\n",
        "- **Example Selection**: Using K-means clustering for diverse examples\n",
        "- **Dynamic Prompting**: Selecting most relevant examples per input using TF-IDF similarity\n",
        "- **Prompt Format**: Added clear instruction header and example delimiters\n",
        "- **Comparison**: Evaluated fixed vs. dynamic prompting effectiveness\n",
        "\n",
        "## 4. Code Structure & Experiment Tracking\n",
        "- **Modularization**: Clean separation between data prep, model training, and evaluation\n",
        "- **Experiment Artifacts**: All models, tokenizers, and results saved with timestamps\n",
        "- **Visualization**: Added plots for key metrics to analyze model performance\n",
        "- **Extensibility**: Code structured for easy parameter tuning and comparison\n",
        "\n",
        "## 5. Additional Metrics\n",
        "- **METEOR Score**: Added alongside BLEU for better translation quality assessment\n",
        "- **Linguistic Analysis**: Detailed tracking of formal/informal markers by category\n",
        "- **Visual Analysis**: Plots showing relationship between metrics\n",
        "\n",
        "These improvements work together to create a more effective, stable, and reliable formality translation model with better output quality."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2941ff27",
      "metadata": {
        "id": "2941ff27"
      },
      "source": [
        "# ðŸš€ Recommended Next Steps\n",
        "\n",
        "To further improve the formality translation model, consider these advanced techniques:\n",
        "\n",
        "## 1. Architecture Improvements\n",
        "- **Larger Models**: Experiment with GPT-2 large or GPT-Neo for improved performance\n",
        "- **Different Base Models**: Test T5 or BART which are designed for sequence-to-sequence tasks\n",
        "- **Adapter Tuning**: Compare different parameter-efficient tuning methods (LoRA vs. Adapters vs. Prefix tuning)\n",
        "\n",
        "## 2. Data Enhancements\n",
        "- **Data Augmentation**: Create synthetic examples by applying rule-based formality transformations\n",
        "- **Active Learning**: Collect human feedback on model outputs to improve training data\n",
        "- **Contrastive Learning**: Train the model to distinguish between formal and informal texts\n",
        "\n",
        "## 3. Training Refinements\n",
        "- **Hyperparameter Search**: Use Bayesian optimization to find optimal training parameters\n",
        "- **Reinforcement Learning**: Apply RLHF (Reinforcement Learning from Human Feedback) for better outputs\n",
        "- **Curriculum Learning**: Start with simple transformations and gradually increase complexity\n",
        "\n",
        "## 4. Evaluation Enhancements\n",
        "- **Human Evaluation**: Set up a blind test with human judges to rate formality and adequacy\n",
        "- **Style Transfer Metrics**: Implement specialized metrics for formality transfer like F-BLEU\n",
        "- **Classifier-based Evaluation**: Train a formal/informal classifier and use it to score outputs\n",
        "\n",
        "## 5. Deployment Considerations\n",
        "- **Model Compression**: Quantize the model to 4-bit precision for faster inference\n",
        "- **Caching**: Implement response caching for common inputs\n",
        "- **API Wrapper**: Build a simple REST API for easy integration with applications\n",
        "\n",
        "By implementing these advanced techniques, your formality translation model could achieve even higher quality outputs and better efficiency."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "825433cb5b4a487a8cc299ddca8fad70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d9c1ea43d0c47b599de7984e215d31b",
              "IPY_MODEL_053392141e9a43778c5a0bc8dcf78dd0",
              "IPY_MODEL_cf26b3630a1546059c6b9682fe4c9308"
            ],
            "layout": "IPY_MODEL_d32afa71f4594213878bff7b4ac47018"
          }
        },
        "7d9c1ea43d0c47b599de7984e215d31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d31040d623d4562b734c54fa68cee79",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_11f230f6358644cc85013e0debd66a03",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "053392141e9a43778c5a0bc8dcf78dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eb9eacbded6488589291a22b6d2a55f",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0f57e17b24b44a693f1aa8c3499c432",
            "value": 26
          }
        },
        "cf26b3630a1546059c6b9682fe4c9308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d2934371eb045a2a242f65f02c1d254",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e1fcfce1db9e4e429e76ae5327cfbe2a",
            "value": "â€‡26.0/26.0â€‡[00:00&lt;00:00,â€‡3.10kB/s]"
          }
        },
        "d32afa71f4594213878bff7b4ac47018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d31040d623d4562b734c54fa68cee79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f230f6358644cc85013e0debd66a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3eb9eacbded6488589291a22b6d2a55f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f57e17b24b44a693f1aa8c3499c432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d2934371eb045a2a242f65f02c1d254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1fcfce1db9e4e429e76ae5327cfbe2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac6898adb1314518ae3a5b7413a43e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3b45925bb2047d78ec23c387319d5da",
              "IPY_MODEL_55f9d9fd22c8483a9d7b79bf46e9ad41",
              "IPY_MODEL_9302506d1299493c8501a1a00f172ca7"
            ],
            "layout": "IPY_MODEL_d349313678864a5897b29bec9a687375"
          }
        },
        "d3b45925bb2047d78ec23c387319d5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7ccbfc893834280a8910946eeb77eb1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c87179190a4f4af686c1fc39fc6a8882",
            "value": "config.json:â€‡100%"
          }
        },
        "55f9d9fd22c8483a9d7b79bf46e9ad41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46bb39dff5d9440d873f1750ce9d04db",
            "max": 718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a0055dcb7f142cdb94f8be7d490a643",
            "value": 718
          }
        },
        "9302506d1299493c8501a1a00f172ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a6fce6d2b2d4f3c915e1c9eb7dc52a7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6b8db0a31b484428a8cc0fcfa04ae183",
            "value": "â€‡718/718â€‡[00:00&lt;00:00,â€‡85.6kB/s]"
          }
        },
        "d349313678864a5897b29bec9a687375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7ccbfc893834280a8910946eeb77eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87179190a4f4af686c1fc39fc6a8882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46bb39dff5d9440d873f1750ce9d04db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a0055dcb7f142cdb94f8be7d490a643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a6fce6d2b2d4f3c915e1c9eb7dc52a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b8db0a31b484428a8cc0fcfa04ae183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f72b9f0e0294aa38b1225cfece743ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a5dd5fcf4694e9a9c7a82d09637347f",
              "IPY_MODEL_fa30f264c036496ea63d4efce1ea713b",
              "IPY_MODEL_9504162b57e046789328b831eb5637dd"
            ],
            "layout": "IPY_MODEL_faba07a0eab1470b95c6693a1aa479f6"
          }
        },
        "0a5dd5fcf4694e9a9c7a82d09637347f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc2f444d34a744908aa6484b13dc4ed2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ea035f14de5b47f89449aca14413d932",
            "value": "vocab.json:â€‡100%"
          }
        },
        "fa30f264c036496ea63d4efce1ea713b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2f9396dc8b44d159d1035a2da7672d7",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08fd69a06ec54d4d895432b00ade1529",
            "value": 1042301
          }
        },
        "9504162b57e046789328b831eb5637dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08ab68ea954f4427befb106e39d1b134",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c96915028fe247079c643c2971869bb0",
            "value": "â€‡1.04M/1.04Mâ€‡[00:00&lt;00:00,â€‡14.2MB/s]"
          }
        },
        "faba07a0eab1470b95c6693a1aa479f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc2f444d34a744908aa6484b13dc4ed2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea035f14de5b47f89449aca14413d932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2f9396dc8b44d159d1035a2da7672d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08fd69a06ec54d4d895432b00ade1529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08ab68ea954f4427befb106e39d1b134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c96915028fe247079c643c2971869bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8267af0a9624d3e824b43a7cf8e1123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be46810390784274b758707391739cee",
              "IPY_MODEL_29d3e84a56634b3b873839dbc4ae6f27",
              "IPY_MODEL_a1291f326b5940b8ad083c091be80565"
            ],
            "layout": "IPY_MODEL_50000590f60442a5a107b436e5184578"
          }
        },
        "be46810390784274b758707391739cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7ee13182cf44ad78f1d557d940877d8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ed0dbf86c31a46d3886818061b532fd9",
            "value": "merges.txt:â€‡100%"
          }
        },
        "29d3e84a56634b3b873839dbc4ae6f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3890e8c706742cbb49ef24706dec811",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba11d2274b9d4b9aa10270bd78bbdce6",
            "value": 456318
          }
        },
        "a1291f326b5940b8ad083c091be80565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3fb3f064dd415bb0786f6f02209c76",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5b6b1efb82bc4d799e59fbb6c29cf29b",
            "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡38.0MB/s]"
          }
        },
        "50000590f60442a5a107b436e5184578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7ee13182cf44ad78f1d557d940877d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed0dbf86c31a46d3886818061b532fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3890e8c706742cbb49ef24706dec811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba11d2274b9d4b9aa10270bd78bbdce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c3fb3f064dd415bb0786f6f02209c76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b6b1efb82bc4d799e59fbb6c29cf29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b32dc32b2dd2432da1b2adfb18a4a4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb569f9fb7a74db193614b6283747cce",
              "IPY_MODEL_c1469be0cdb344aba73f04b09f83eb87",
              "IPY_MODEL_fff08127612b4beda2505677b85574d5"
            ],
            "layout": "IPY_MODEL_92b89bd9314843aaad237c08e7aa5261"
          }
        },
        "fb569f9fb7a74db193614b6283747cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53541bfe91e4c2cadf9bc975bfce5aa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1fb5da3ab4894fa48f917f5039c3cff7",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "c1469be0cdb344aba73f04b09f83eb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc380f0cd19145cebb741dbb5eec4339",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1db67f37a20484c8f8e0e736b669cae",
            "value": 1355256
          }
        },
        "fff08127612b4beda2505677b85574d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ed20ba9f035495d8b0484b36817172c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a0531d03e3664707ae16bc2fb6fa8322",
            "value": "â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡5.11MB/s]"
          }
        },
        "92b89bd9314843aaad237c08e7aa5261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b53541bfe91e4c2cadf9bc975bfce5aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb5da3ab4894fa48f917f5039c3cff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc380f0cd19145cebb741dbb5eec4339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1db67f37a20484c8f8e0e736b669cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ed20ba9f035495d8b0484b36817172c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0531d03e3664707ae16bc2fb6fa8322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99aa9ca1fc30410899a995f13f117be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ff43e21bfe94738892b49eb962289ed",
              "IPY_MODEL_2b2ac848091048199c06056f485f82c9",
              "IPY_MODEL_14a42497afb441fdbad18db405438df1"
            ],
            "layout": "IPY_MODEL_60d659ac08344b37a4a19106c4842ccd"
          }
        },
        "1ff43e21bfe94738892b49eb962289ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7addd757c6644ab7a2d692b9d2386081",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d5c90ed874714cdd8d5f4d25c8085074",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "2b2ac848091048199c06056f485f82c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_601a9d31dc8b4a15a1899d01047215a3",
            "max": 1519984962,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca7cc6940c0c4258b7dfc21bc92d12f1",
            "value": 1519984962
          }
        },
        "14a42497afb441fdbad18db405438df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f49533b0124a25a1b4bb4c010a0f54",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8d902a1808cc48e5be0060e12a0db403",
            "value": "â€‡1.52G/1.52Gâ€‡[00:05&lt;00:00,â€‡467MB/s]"
          }
        },
        "60d659ac08344b37a4a19106c4842ccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7addd757c6644ab7a2d692b9d2386081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5c90ed874714cdd8d5f4d25c8085074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "601a9d31dc8b4a15a1899d01047215a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7cc6940c0c4258b7dfc21bc92d12f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64f49533b0124a25a1b4bb4c010a0f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d902a1808cc48e5be0060e12a0db403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b190c46be0b405096a305faf83b3a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b4672d02bcb47d191029bc703bd665e",
              "IPY_MODEL_71ef382cb2144f6794585051d6b4bd09",
              "IPY_MODEL_776dbe11845c4c3787283463707388b0"
            ],
            "layout": "IPY_MODEL_1b563632434a43388645f4d85af8b675"
          }
        },
        "6b4672d02bcb47d191029bc703bd665e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c134ea7cb5af4238ba09810241b65bc5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d8874f6f3f1941faa89a06631c5b6fb1",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "71ef382cb2144f6794585051d6b4bd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bc3b1e0a384491590a2d9029376f041",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfbc402cd9e84df39435992e40ad9133",
            "value": 124
          }
        },
        "776dbe11845c4c3787283463707388b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d394b63d1aa47979f172027a679b01e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d93d809f49334e11a46edd7bab2cea1e",
            "value": "â€‡124/124â€‡[00:00&lt;00:00,â€‡15.0kB/s]"
          }
        },
        "1b563632434a43388645f4d85af8b675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c134ea7cb5af4238ba09810241b65bc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8874f6f3f1941faa89a06631c5b6fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bc3b1e0a384491590a2d9029376f041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfbc402cd9e84df39435992e40ad9133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d394b63d1aa47979f172027a679b01e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d93d809f49334e11a46edd7bab2cea1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7361f41637b3410c812a3544fa556ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7546622054174d2eb391f912e44f26d6",
              "IPY_MODEL_bfe42c90103e4c02b6998004dedb9525",
              "IPY_MODEL_6e4d9acacde54a5590c0b0854d320dc1"
            ],
            "layout": "IPY_MODEL_43900a9b19484aef8df9a31a1ef71dc1"
          }
        },
        "7546622054174d2eb391f912e44f26d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df0465a63a234401a52c2cf09a213351",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_42b08478acd54178a69fc1e02750fd60",
            "value": "Convertingâ€‡trainâ€‡datasetâ€‡toâ€‡ChatML:â€‡100%"
          }
        },
        "bfe42c90103e4c02b6998004dedb9525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b2ce1daedbf446babcdb1452b18e471",
            "max": 1596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc72c781ef6649c491b81dbd354ad5c0",
            "value": 1596
          }
        },
        "6e4d9acacde54a5590c0b0854d320dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e05a81bc9d14fb7b8c80e811571cdf6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_09d123b9978548ebaabccccd58be5733",
            "value": "â€‡1596/1596â€‡[00:00&lt;00:00,â€‡30157.45â€‡examples/s]"
          }
        },
        "43900a9b19484aef8df9a31a1ef71dc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df0465a63a234401a52c2cf09a213351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42b08478acd54178a69fc1e02750fd60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b2ce1daedbf446babcdb1452b18e471": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc72c781ef6649c491b81dbd354ad5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e05a81bc9d14fb7b8c80e811571cdf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09d123b9978548ebaabccccd58be5733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62200d040dda402580705ebaa47425e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2f020cfc8414c71a0ae559a69947b65",
              "IPY_MODEL_867249d26e4743f0b720f6db79795777",
              "IPY_MODEL_0c149a6aca6b4382b922b0d20fb63b2b"
            ],
            "layout": "IPY_MODEL_d3bb7e7809a14d978422f7d1511a4244"
          }
        },
        "c2f020cfc8414c71a0ae559a69947b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d59eb40e1964f29a798dbe34ef6a3b4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_56e4db855ca64e47ac081844f1d67e82",
            "value": "Addingâ€‡EOSâ€‡toâ€‡trainâ€‡dataset:â€‡100%"
          }
        },
        "867249d26e4743f0b720f6db79795777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a25c5937250436685eec45f856b774b",
            "max": 1596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f218121b4245462788b75cd0e81dbd25",
            "value": 1596
          }
        },
        "0c149a6aca6b4382b922b0d20fb63b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e983bc0149be443a94dca866ba291379",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_186b0b2ae90a4fab892cf613d5c3c769",
            "value": "â€‡1596/1596â€‡[00:00&lt;00:00,â€‡20987.69â€‡examples/s]"
          }
        },
        "d3bb7e7809a14d978422f7d1511a4244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d59eb40e1964f29a798dbe34ef6a3b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56e4db855ca64e47ac081844f1d67e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a25c5937250436685eec45f856b774b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f218121b4245462788b75cd0e81dbd25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e983bc0149be443a94dca866ba291379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "186b0b2ae90a4fab892cf613d5c3c769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3148759d4b59496eb9ca21920a8dc2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6be4cdbf9d994f6c83b286e05ff631a5",
              "IPY_MODEL_48316d6848bf4b1ea4c94e333f95cc6d",
              "IPY_MODEL_bfcd5f0804f64e37908c0f4329c0d27e"
            ],
            "layout": "IPY_MODEL_5edc4663b9c94bff94cd3da4b16c4ab8"
          }
        },
        "6be4cdbf9d994f6c83b286e05ff631a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_646247fe3123495a888a9c06246edd55",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3842ef75165a431c9478c7fb229df75b",
            "value": "Tokenizingâ€‡trainâ€‡dataset:â€‡100%"
          }
        },
        "48316d6848bf4b1ea4c94e333f95cc6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8094656b70444969b2c455ad15b34746",
            "max": 1596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16defce03be9455eba4e2dcbd0f0742c",
            "value": 1596
          }
        },
        "bfcd5f0804f64e37908c0f4329c0d27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b1ab92b873b4fe6b40f7312842b313f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_13e0b238e6ad487d8a02e278e0b11864",
            "value": "â€‡1596/1596â€‡[00:02&lt;00:00,â€‡804.05â€‡examples/s]"
          }
        },
        "5edc4663b9c94bff94cd3da4b16c4ab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "646247fe3123495a888a9c06246edd55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3842ef75165a431c9478c7fb229df75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8094656b70444969b2c455ad15b34746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16defce03be9455eba4e2dcbd0f0742c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b1ab92b873b4fe6b40f7312842b313f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13e0b238e6ad487d8a02e278e0b11864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f60401db3fd0423b91862511c48f474c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b37c68607594284b0d6a99ebaf50349",
              "IPY_MODEL_c4880610bebd4036a19c4f2c6bf8f547",
              "IPY_MODEL_8ac1e706e75d47a8875ed319fc8f7ac9"
            ],
            "layout": "IPY_MODEL_c2c45ad336254db28b803540021526b2"
          }
        },
        "9b37c68607594284b0d6a99ebaf50349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7949c2ecf6dd496093521de511729dea",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_84ad481c00e84f37949190ef74983be6",
            "value": "Truncatingâ€‡trainâ€‡dataset:â€‡100%"
          }
        },
        "c4880610bebd4036a19c4f2c6bf8f547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2eef878af4f494cab3aa6fa848c4e64",
            "max": 1596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac0164e9bbab430cbbebe911ae9bd2ee",
            "value": 1596
          }
        },
        "8ac1e706e75d47a8875ed319fc8f7ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6933b98d04fd46b1b41ba9c2080f08b5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_50e80d9571ee4492b2f7fa0746bd875e",
            "value": "â€‡1596/1596â€‡[00:00&lt;00:00,â€‡75266.30â€‡examples/s]"
          }
        },
        "c2c45ad336254db28b803540021526b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7949c2ecf6dd496093521de511729dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ad481c00e84f37949190ef74983be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2eef878af4f494cab3aa6fa848c4e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac0164e9bbab430cbbebe911ae9bd2ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6933b98d04fd46b1b41ba9c2080f08b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50e80d9571ee4492b2f7fa0746bd875e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b52107cf662042518fc8491bdcb99d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a607870539b4775a7179cf2039440f0",
              "IPY_MODEL_0071d07cbb464ef1bf0013f1318a8667",
              "IPY_MODEL_e59ebec1a1c44c3383a758362c40e3c6"
            ],
            "layout": "IPY_MODEL_a48267d4a5d640f097121392c28872b5"
          }
        },
        "9a607870539b4775a7179cf2039440f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a780120363945d2bb03df6ea7a8ca1e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ea8d70c31aac4b4f96b211d1b314b88f",
            "value": "Convertingâ€‡evalâ€‡datasetâ€‡toâ€‡ChatML:â€‡100%"
          }
        },
        "0071d07cbb464ef1bf0013f1318a8667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ec66c3a097472daf2e2f07f153e36b",
            "max": 399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dab395e58e5d443db6d0ee5c9f59a8a1",
            "value": 399
          }
        },
        "e59ebec1a1c44c3383a758362c40e3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a374deff01245d0b1fe1d01c2dcdcb0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1362040b90be4862ad460d865729b749",
            "value": "â€‡399/399â€‡[00:00&lt;00:00,â€‡19650.18â€‡examples/s]"
          }
        },
        "a48267d4a5d640f097121392c28872b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a780120363945d2bb03df6ea7a8ca1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea8d70c31aac4b4f96b211d1b314b88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4ec66c3a097472daf2e2f07f153e36b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab395e58e5d443db6d0ee5c9f59a8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a374deff01245d0b1fe1d01c2dcdcb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1362040b90be4862ad460d865729b749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a981d98238c4df698ebf6c1f2c5a3f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f020570191604a8d9f22bce040ffa4e0",
              "IPY_MODEL_eb789710462a4564bb26c5d4b25d1cd4",
              "IPY_MODEL_656f9fef43ee476d97402b8bf4ca6e8a"
            ],
            "layout": "IPY_MODEL_49bc9b56565e4860b04f70b0a697a70c"
          }
        },
        "f020570191604a8d9f22bce040ffa4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ebd9763f3254c7da0beec43b7338910",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_770993eadade430c8b60ce77817e859a",
            "value": "Addingâ€‡EOSâ€‡toâ€‡evalâ€‡dataset:â€‡100%"
          }
        },
        "eb789710462a4564bb26c5d4b25d1cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48b4ae3578604b4880546d302b9a8a0e",
            "max": 399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35f9f43431e04a52b7420109ac42756f",
            "value": 399
          }
        },
        "656f9fef43ee476d97402b8bf4ca6e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3064ce77a76a4036a2f8eadc170b61e7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ff89dc7fb6f14a06b49ad46f09c7ceb8",
            "value": "â€‡399/399â€‡[00:00&lt;00:00,â€‡14547.10â€‡examples/s]"
          }
        },
        "49bc9b56565e4860b04f70b0a697a70c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ebd9763f3254c7da0beec43b7338910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "770993eadade430c8b60ce77817e859a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48b4ae3578604b4880546d302b9a8a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35f9f43431e04a52b7420109ac42756f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3064ce77a76a4036a2f8eadc170b61e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff89dc7fb6f14a06b49ad46f09c7ceb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa5734f48688402e8468451759015064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9b2ce4dc75f49db9941da3dd2bbe632",
              "IPY_MODEL_d016126f78ec4c31853994e08f851c3a",
              "IPY_MODEL_2aefb8fc5da14b548e7ed426de42fa1d"
            ],
            "layout": "IPY_MODEL_86e0d3a8d7c3428bac445daf45580b83"
          }
        },
        "d9b2ce4dc75f49db9941da3dd2bbe632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76034b03fb6846dd927bcfc7ccd0a7b5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7f408cf433604ed599462bae6e72df36",
            "value": "Tokenizingâ€‡evalâ€‡dataset:â€‡100%"
          }
        },
        "d016126f78ec4c31853994e08f851c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_949f61f295684516832800eee2dad1a8",
            "max": 399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de2c3ac50c0b467b84c2b232004402f0",
            "value": 399
          }
        },
        "2aefb8fc5da14b548e7ed426de42fa1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6aab631a43f4dd6a9a2e471c5f76ac2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_828fc1ccb364490bb4c28c3f268c78d0",
            "value": "â€‡399/399â€‡[00:00&lt;00:00,â€‡844.63â€‡examples/s]"
          }
        },
        "86e0d3a8d7c3428bac445daf45580b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76034b03fb6846dd927bcfc7ccd0a7b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f408cf433604ed599462bae6e72df36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "949f61f295684516832800eee2dad1a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de2c3ac50c0b467b84c2b232004402f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6aab631a43f4dd6a9a2e471c5f76ac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "828fc1ccb364490bb4c28c3f268c78d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "648fb93194694ce2a74471b7d7945f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2670228e21ea44da965cc78a9f629853",
              "IPY_MODEL_470ffd446bd84bbd8f5f3f7b05847c56",
              "IPY_MODEL_fb22109ef9924dd5a94a3dbcc768648b"
            ],
            "layout": "IPY_MODEL_46aff7397feb42edb37a73544aed4022"
          }
        },
        "2670228e21ea44da965cc78a9f629853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccbb7a59b7224164a32a95de49bc7d9f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_54b7a16c540d472884fc1f75f8a66f0d",
            "value": "Truncatingâ€‡evalâ€‡dataset:â€‡100%"
          }
        },
        "470ffd446bd84bbd8f5f3f7b05847c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d7736ef385647479aac7c407db26496",
            "max": 399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0626eef493854f099c44610f3c8f2ab8",
            "value": 399
          }
        },
        "fb22109ef9924dd5a94a3dbcc768648b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1f0ba937d3c4bc9bca1fa06e4e9a583",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b11c727bcf3c483391e839bf2ce3bbba",
            "value": "â€‡399/399â€‡[00:00&lt;00:00,â€‡33315.30â€‡examples/s]"
          }
        },
        "46aff7397feb42edb37a73544aed4022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccbb7a59b7224164a32a95de49bc7d9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54b7a16c540d472884fc1f75f8a66f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d7736ef385647479aac7c407db26496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0626eef493854f099c44610f3c8f2ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1f0ba937d3c4bc9bca1fa06e4e9a583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11c727bcf3c483391e839bf2ce3bbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}