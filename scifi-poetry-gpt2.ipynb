{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hearlvein/colab/blob/main/guten_tag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e78fb2",
      "metadata": {
        "id": "85e78fb2"
      },
      "source": [
        "# ü™ê Fine-Tuning GPT-2 with LoRA for Poetic Sci-Fi/Fantasy Story Generation\n",
        "\n",
        "This notebook guides you through fine-tuning GPT-2 using Low-Rank Adaptation (LoRA) to generate poetic sci-fi/fantasy short stories. The process includes:\n",
        "- Dataset preparation from Project Gutenberg\n",
        "- Model fine-tuning with LoRA\n",
        "- Story generation based on user prompts\n",
        "\n",
        "**Note:** This notebook is designed for execution in Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38cb754d",
      "metadata": {
        "id": "38cb754d"
      },
      "source": [
        "## üîß Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4dc4a906",
      "metadata": {
        "id": "4dc4a906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-keras in c:\\users\\james\\anaconda3\\lib\\site-packages (2.19.0)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tf-keras) (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.2.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.11.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\james\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.44.0)\n",
            "Requirement already satisfied: rich in c:\\users\\james\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\james\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.9)\n",
            "Requirement already satisfied: optree in c:\\users\\james\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "!pip install -q transformers datasets peft trl bitsandbytes accelerate\n",
        "!pip install -q beautifulsoup4 requests gutenbergpy\n",
        "!pip install tf-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05b944d2",
      "metadata": {
        "id": "05b944d2"
      },
      "source": [
        "## üìö Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ae02ca8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae02ca8a",
        "outputId": "124b1b9b-4bcc-42ac-b1b0-85cce6dfa00b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Gutenberg metadata cache...\n",
            "Book 145 already exists at gutenberg_dataset\\science_fiction\\145.txt, skipping download.\n",
            "Book 2160 already exists at gutenberg_dataset\\science_fiction\\2160.txt, skipping download.\n",
            "Book 4085 already exists at gutenberg_dataset\\science_fiction\\4085.txt, skipping download.\n",
            "Book 1259 already exists at gutenberg_dataset\\science_fiction\\1259.txt, skipping download.\n",
            "Book 98 already exists at gutenberg_dataset\\science_fiction\\98.txt, skipping download.\n",
            "Book 2600 already exists at gutenberg_dataset\\science_fiction\\2600.txt, skipping download.\n",
            "Book 135 already exists at gutenberg_dataset\\science_fiction\\135.txt, skipping download.\n",
            "Book 120 already exists at gutenberg_dataset\\science_fiction\\120.txt, skipping download.\n",
            "Book 1837 already exists at gutenberg_dataset\\science_fiction\\1837.txt, skipping download.\n",
            "Book 599 already exists at gutenberg_dataset\\science_fiction\\599.txt, skipping download.\n",
            "Loading Gutenberg metadata cache...\n",
            "Book 16328 already exists at gutenberg_dataset\\poetry\\16328.txt, skipping download.\n",
            "Book 1322 already exists at gutenberg_dataset\\poetry\\1322.txt, skipping download.\n",
            "Book 14568 already exists at gutenberg_dataset\\poetry\\14568.txt, skipping download.\n",
            "Book 228 already exists at gutenberg_dataset\\poetry\\228.txt, skipping download.\n",
            "Book 2490 already exists at gutenberg_dataset\\poetry\\2490.txt, skipping download.\n",
            "Book 9622 already exists at gutenberg_dataset\\poetry\\9622.txt, skipping download.\n",
            "Book 20 already exists at gutenberg_dataset\\poetry\\20.txt, skipping download.\n",
            "Book 3333 already exists at gutenberg_dataset\\poetry\\3333.txt, skipping download.\n",
            "Book 1321 already exists at gutenberg_dataset\\poetry\\1321.txt, skipping download.\n",
            "Downloading book ID 23979...\n",
            "Loading Gutenberg metadata cache...\n",
            "Book 16328 already exists at gutenberg_dataset\\poetry\\16328.txt, skipping download.\n",
            "Book 1322 already exists at gutenberg_dataset\\poetry\\1322.txt, skipping download.\n",
            "Book 14568 already exists at gutenberg_dataset\\poetry\\14568.txt, skipping download.\n",
            "Book 228 already exists at gutenberg_dataset\\poetry\\228.txt, skipping download.\n",
            "Book 2490 already exists at gutenberg_dataset\\poetry\\2490.txt, skipping download.\n",
            "Book 9622 already exists at gutenberg_dataset\\poetry\\9622.txt, skipping download.\n",
            "Book 20 already exists at gutenberg_dataset\\poetry\\20.txt, skipping download.\n",
            "Book 3333 already exists at gutenberg_dataset\\poetry\\3333.txt, skipping download.\n",
            "Book 1321 already exists at gutenberg_dataset\\poetry\\1321.txt, skipping download.\n",
            "Downloading book ID 23979...\n",
            "Error downloading book 23979: exceptions must derive from BaseException\n",
            "Error downloading book 23979: exceptions must derive from BaseException\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from gutenbergpy.textget import get_text_by_id\n",
        "from gutenbergpy.gutenbergcache import GutenbergCache\n",
        "\n",
        "\n",
        "# Define genres and corresponding Project Gutenberg bookshelf URLs\n",
        "bookshelves = {\n",
        "    'science_fiction': 'https://www.gutenberg.org/ebooks/bookshelf/41',\n",
        "    'poetry': 'https://www.gutenberg.org/ebooks/bookshelf/60',\n",
        "}\n",
        "\n",
        "# Function to extract book IDs from a Project Gutenberg bookshelf\n",
        "def get_book_ids_from_bookshelf(url, limit=10):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    book_links = soup.select('li.booklink a.link')\n",
        "    book_ids = []\n",
        "\n",
        "    for link in book_links:\n",
        "        href = link.get('href')\n",
        "        if href.startswith('/ebooks/'):\n",
        "            book_id = href.split('/')[-1]\n",
        "            if book_id.isdigit():\n",
        "                book_ids.append(int(book_id))\n",
        "                if len(book_ids) == limit:\n",
        "                    break\n",
        "    return book_ids\n",
        "\n",
        "# Function to download book texts given their IDs\n",
        "def download_books(book_ids, output_folder):\n",
        "    from gutenbergpy.textget import get_text_by_id\n",
        "    from gutenbergpy.gutenbergcache import GutenbergCache\n",
        "\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    print(\"Loading Gutenberg metadata cache...\")\n",
        "    cache = GutenbergCache.get_cache()\n",
        "    for book_id in book_ids:\n",
        "        output_path = os.path.join(output_folder, f\"{book_id}.txt\")\n",
        "        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:\n",
        "            print(f\"Book {book_id} already exists at {output_path}, skipping download.\")\n",
        "            continue\n",
        "        print(f\"Downloading book ID {book_id}...\")\n",
        "        try:\n",
        "            text_bytes = get_text_by_id(book_id)\n",
        "            text_str = text_bytes.decode('utf-8', errors='ignore')\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(text_str)\n",
        "            print(f\"Saved book {book_id} to {output_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading book {book_id}: {e}\")\n",
        "\n",
        "# Utility function to download books by genre\n",
        "def download_books_to_dataset(bookshelf_url, genre, limit=10, base_folder=\"gutenberg_dataset\"):\n",
        "    output_folder = os.path.join(base_folder, genre)\n",
        "    book_ids = get_book_ids_from_bookshelf(bookshelf_url, limit=limit)\n",
        "    download_books(book_ids, output_folder=output_folder)\n",
        "\n",
        "# Download books for each genre\n",
        "for genre, url in bookshelves.items():\n",
        "    download_books_to_dataset(url, genre=genre, limit=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc1261d4",
      "metadata": {
        "id": "cc1261d4"
      },
      "source": [
        "## üßπ Data Cleaning and JSONL Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "826ddea3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "826ddea3",
        "outputId": "0f6953de-8275-4808-a76c-76a6c4dfbc41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gutenberg_dataset.jsonl already exists and is non-empty, skipping processing.\n",
            "Dataset written to gutenberg_dataset.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Define input directories and output file\n",
        "INPUT_DIRS = {\n",
        "    \"science_fiction\": Path(\"gutenberg_dataset/science_fiction\"),\n",
        "    \"poetry\": Path(\"gutenberg_dataset/poetry\"),\n",
        "}\n",
        "OUTPUT_FILE = Path(\"gutenberg_dataset.jsonl\")\n",
        "\n",
        "# Regex patterns to remove Project Gutenberg headers/footers\n",
        "HEADER_PATTERN = re.compile(\n",
        "    r\"\\*{3}\\s*START OF THIS PROJECT GUTENBERG EBOOK.*?\\*{3}\", re.IGNORECASE | re.DOTALL\n",
        ")\n",
        "FOOTER_PATTERN = re.compile(\n",
        "    r\"\\*{3}\\s*END OF THIS PROJECT GUTENBERG EBOOK.*\", re.IGNORECASE | re.DOTALL\n",
        ")\n",
        "\n",
        "# Function to clean Gutenberg text\n",
        "def clean_gutenberg_text(text: str) -> str:\n",
        "    text = HEADER_PATTERN.sub(\"\", text)\n",
        "    text = FOOTER_PATTERN.sub(\"\", text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Function to process and write data to JSONL\n",
        "def process_and_write_jsonl(input_dirs: dict, output_path: Path):\n",
        "    if output_path.exists() and output_path.stat().st_size > 0:\n",
        "        print(f\"{output_path} already exists and is non-empty, skipping processing.\")\n",
        "        return\n",
        "    with output_path.open(\"w\", encoding=\"utf-8\") as out_file:\n",
        "        for source_label, folder in input_dirs.items():\n",
        "            txt_files = list(folder.rglob(\"*.txt\"))\n",
        "            for txt_path in tqdm(txt_files, desc=f\"Processing {source_label}\"):\n",
        "                try:\n",
        "                    raw = txt_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "                    clean = clean_gutenberg_text(raw)\n",
        "                    if not clean:\n",
        "                        continue\n",
        "                    record = {\n",
        "                        \"source\": source_label,\n",
        "                        \"filename\": txt_path.name,\n",
        "                        \"text\": clean,\n",
        "                    }\n",
        "                    out_file.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {txt_path}: {e}\")\n",
        "\n",
        "# Process and write the dataset\n",
        "os.makedirs(OUTPUT_FILE.parent, exist_ok=True)\n",
        "process_and_write_jsonl(INPUT_DIRS, OUTPUT_FILE)\n",
        "print(f\"Dataset written to {OUTPUT_FILE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7a42369",
      "metadata": {
        "id": "f7a42369"
      },
      "source": [
        "## üß† Model Fine-Tuning with LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceb3d2ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "d4025865aee842d3a1800d6d73f5b967",
            "a77ad0df19044006bd28b8fb9a7c75a4",
            "1d7cd2e8f16b437092907e4e4ac5efff",
            "ab2f8044a2424aeb968ea8d413544b32",
            "43e891bb8a39471db48409ccce97ac8f",
            "3d88fa454c924aebbcdfdc74d409f372",
            "0ec92b52a92a45e782d98c7161222a02",
            "b0c31407646c43d8bc5b95fb766bbe76",
            "2293c5c237d74ef2b1ef74c2bbbc4769",
            "d5ff4d95965e4f8fb9a6afb72860aa3e",
            "e36569878fe94db08cdb8a3c59dbaa30",
            "6f8597d2e4cb43d9a30ff28ac8df03e6",
            "6377c17056a4427186f6748e7267bafa",
            "66ae97084fd9427ea5d32487a36a3926",
            "40f6bd5d16b24438a6da93eae747bfdb",
            "90a683bae74248678f42f6c7dcd14ea6",
            "e546d71c76bb4fec95b79aa8dcadb96d",
            "cf0ab7078ff94452ab29546a88c469b0",
            "270be6f139d14bf79bf4bac0d35e7126",
            "8207f2b8287d49b3920bb30631cacc50",
            "659b2f0f68d443b59c0b254b30c091d0",
            "b8574c2651fd4a3492e6730741105b78"
          ]
        },
        "id": "ceb3d2ce",
        "outputId": "5d9da6a6-8f62-4844-de44-9d7a4b45b319"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded with 20 records.\n",
            "Using device: cpu\n",
            "Quantization not available (Not using CUDA, falling back to regular loading), falling back to regular model loading...\n",
            "Using device: cpu\n",
            "Quantization not available (Not using CUDA, falling back to regular loading), falling back to regular model loading...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a760d88172643c4b41e5f22a49f9ebe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9b5fb5ae6f540daabdc23d18fc4569a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using regular model loading without quantization\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\james\\anaconda3\\Lib\\site-packages\\peft\\tuners\\lora\\layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abb2cb4932d44ed3a463ef433f5b367c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "794d747a0c9248a8870dc148e6b46f8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/30 01:15 < 02:40, 0.12 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
        "from peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "# Load the dataset\n",
        "print(\"Loading dataset...\")\n",
        "with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:\n",
        "    data = [json.loads(line) for line in f if line.strip()]\n",
        "dataset = Dataset.from_list(data)\n",
        "print(f\"Dataset loaded with {len(dataset)} records.\")\n",
        "\n",
        "# Load tokenizer and model\n",
        "MODEL_NAME = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Check device availability and configure model loading accordingly\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Try to use quantization if supported, otherwise fall back to regular loading\n",
        "try:\n",
        "    if device == \"cuda\":\n",
        "        # Load model with 8-bit precision for CUDA\n",
        "        bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_NAME, \n",
        "            quantization_config=bnb_config, \n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "        model = prepare_model_for_kbit_training(model)\n",
        "        print(\"Using 8-bit quantization with bitsandbytes\")\n",
        "    else:\n",
        "        raise RuntimeError(\"Not using CUDA, falling back to regular loading\")\n",
        "except Exception as e:\n",
        "    print(f\"Quantization not available ({e}), falling back to regular model loading...\")\n",
        "    # Fallback to regular model loading without quantization\n",
        "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "    model = model.to(device)\n",
        "    print(\"Using regular model loading without quantization\")\n",
        "\n",
        "# Configure LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"c_attn\", \"c_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=1024)\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\", \"filename\", \"source\"])\n",
        "\n",
        "# Adjust batch size based on available memory/device\n",
        "batch_size = 2 if device == \"cpu\" else 4\n",
        "\n",
        "# Create training arguments (SFTConfig wraps TrainingArguments internally)\n",
        "training_args = SFTConfig(\n",
        "    output_dir=\"./poetic_sci_fi_model\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=50,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=(device == \"cuda\"),  # Only use fp16 with CUDA\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        "    overwrite_output_dir=True\n",
        ")\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "model_path = \"./poetic_sci_fi_model\"\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c02f4a9",
      "metadata": {
        "id": "1c02f4a9"
      },
      "source": [
        "## ‚ú® Story Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ffb9c25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ffb9c25",
        "outputId": "36a085c4-679d-431c-9097-4db35c5eb917"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generated Poetic Sci-Fi Story:\n",
            "\n",
            "In the twilight of the cosmos, a lone traveler discovers a hidden world where dreams manifest into reality. But when he's in need of help to find his brother who is also possessed by an unknown spirit, Captain Vastra goes from trying to make sense of what was just described through visions into believing it isn't real and ultimately falling off at last as time runs out for him! And yet this man has already been sent back down with untold vengeance on Earth that fateful night...\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the fine-tuned model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Define a prompt\n",
        "prompt = \"In the twilight of the cosmos, a lone traveler discovers a hidden world where dreams manifest into reality.\"\n",
        "\n",
        "# Generate a story\n",
        "output = generator(\n",
        "    prompt,\n",
        "    max_new_tokens=1000,\n",
        "    do_sample=True,\n",
        "    temperature=0.95,\n",
        "    top_k=50,\n",
        "    top_p=0.92,\n",
        "    repetition_penalty=1.1,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "print(\"\\nGenerated Poetic Sci-Fi Story:\\n\")\n",
        "print(output[0][\"generated_text\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ec92b52a92a45e782d98c7161222a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d7cd2e8f16b437092907e4e4ac5efff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0c31407646c43d8bc5b95fb766bbe76",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2293c5c237d74ef2b1ef74c2bbbc4769",
            "value": 20
          }
        },
        "2293c5c237d74ef2b1ef74c2bbbc4769": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "270be6f139d14bf79bf4bac0d35e7126": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d88fa454c924aebbcdfdc74d409f372": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40f6bd5d16b24438a6da93eae747bfdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_659b2f0f68d443b59c0b254b30c091d0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b8574c2651fd4a3492e6730741105b78",
            "value": "‚Äá20/20‚Äá[00:00&lt;00:00,‚Äá649.99‚Äáexamples/s]"
          }
        },
        "43e891bb8a39471db48409ccce97ac8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6377c17056a4427186f6748e7267bafa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e546d71c76bb4fec95b79aa8dcadb96d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cf0ab7078ff94452ab29546a88c469b0",
            "value": "Truncating‚Äátrain‚Äádataset:‚Äá100%"
          }
        },
        "659b2f0f68d443b59c0b254b30c091d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66ae97084fd9427ea5d32487a36a3926": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_270be6f139d14bf79bf4bac0d35e7126",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8207f2b8287d49b3920bb30631cacc50",
            "value": 20
          }
        },
        "6f8597d2e4cb43d9a30ff28ac8df03e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6377c17056a4427186f6748e7267bafa",
              "IPY_MODEL_66ae97084fd9427ea5d32487a36a3926",
              "IPY_MODEL_40f6bd5d16b24438a6da93eae747bfdb"
            ],
            "layout": "IPY_MODEL_90a683bae74248678f42f6c7dcd14ea6"
          }
        },
        "8207f2b8287d49b3920bb30631cacc50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90a683bae74248678f42f6c7dcd14ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a77ad0df19044006bd28b8fb9a7c75a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d88fa454c924aebbcdfdc74d409f372",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0ec92b52a92a45e782d98c7161222a02",
            "value": "Map:‚Äá100%"
          }
        },
        "ab2f8044a2424aeb968ea8d413544b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5ff4d95965e4f8fb9a6afb72860aa3e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e36569878fe94db08cdb8a3c59dbaa30",
            "value": "‚Äá20/20‚Äá[00:27&lt;00:00,‚Äá‚Äá1.38s/‚Äáexamples]"
          }
        },
        "b0c31407646c43d8bc5b95fb766bbe76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8574c2651fd4a3492e6730741105b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf0ab7078ff94452ab29546a88c469b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4025865aee842d3a1800d6d73f5b967": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a77ad0df19044006bd28b8fb9a7c75a4",
              "IPY_MODEL_1d7cd2e8f16b437092907e4e4ac5efff",
              "IPY_MODEL_ab2f8044a2424aeb968ea8d413544b32"
            ],
            "layout": "IPY_MODEL_43e891bb8a39471db48409ccce97ac8f"
          }
        },
        "d5ff4d95965e4f8fb9a6afb72860aa3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e36569878fe94db08cdb8a3c59dbaa30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e546d71c76bb4fec95b79aa8dcadb96d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
